<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Pytorch的单机多GPU训练 | GoldNotes</title>
    <meta name="generator" content="VuePress 1.9.10">
    <script>
            var _hmt = _hmt || [];
            (function() {
            // 引入谷歌,不需要可删除这段
            var hm1 = document.createElement("script");
            hm1.src = "https://www.googletagmanager.com/gtag/js?id=G-BDK0Y9WWLP";
            var s1 = document.getElementsByTagName("script")[0]; 
            s1.parentNode.insertBefore(hm1, s1);
            })();
            // 谷歌加载,不需要可删除
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-BDK0Y9WWLP');
        </script>
    <link rel="icon" href="/logo.png">
    <script data-ad-client="ca-pub-8685746128991385" async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="Just playing around">
    
    <link rel="preload" href="/assets/css/0.styles.c5e7512f.css" as="style"><link rel="preload" href="/assets/js/app.4fb1e7ac.js" as="script"><link rel="preload" href="/assets/js/2.441eb26f.js" as="script"><link rel="preload" href="/assets/js/1.1a1c696e.js" as="script"><link rel="preload" href="/assets/js/44.01f440d3.js" as="script"><link rel="prefetch" href="/assets/js/10.5a2e9b6f.js"><link rel="prefetch" href="/assets/js/100.ef80225f.js"><link rel="prefetch" href="/assets/js/101.e15d219a.js"><link rel="prefetch" href="/assets/js/102.d6f75c18.js"><link rel="prefetch" href="/assets/js/103.12816430.js"><link rel="prefetch" href="/assets/js/104.7cafc7da.js"><link rel="prefetch" href="/assets/js/105.a95fe706.js"><link rel="prefetch" href="/assets/js/106.f9124e10.js"><link rel="prefetch" href="/assets/js/107.8ff67460.js"><link rel="prefetch" href="/assets/js/108.f9d986f5.js"><link rel="prefetch" href="/assets/js/109.32bd2df3.js"><link rel="prefetch" href="/assets/js/11.3e0edbf0.js"><link rel="prefetch" href="/assets/js/110.313ef3df.js"><link rel="prefetch" href="/assets/js/111.b8637dcf.js"><link rel="prefetch" href="/assets/js/112.9e6011d2.js"><link rel="prefetch" href="/assets/js/113.63c9a458.js"><link rel="prefetch" href="/assets/js/114.50d79414.js"><link rel="prefetch" href="/assets/js/115.f6673090.js"><link rel="prefetch" href="/assets/js/116.a6d8417d.js"><link rel="prefetch" href="/assets/js/117.7e612414.js"><link rel="prefetch" href="/assets/js/118.d92d9409.js"><link rel="prefetch" href="/assets/js/119.ebe75303.js"><link rel="prefetch" href="/assets/js/12.9a49b12f.js"><link rel="prefetch" href="/assets/js/120.552b6b09.js"><link rel="prefetch" href="/assets/js/121.db70210c.js"><link rel="prefetch" href="/assets/js/122.6f43bbfe.js"><link rel="prefetch" href="/assets/js/123.fad382fe.js"><link rel="prefetch" href="/assets/js/124.fc7d5e6b.js"><link rel="prefetch" href="/assets/js/125.644c16a8.js"><link rel="prefetch" href="/assets/js/126.b554f501.js"><link rel="prefetch" href="/assets/js/127.5d9889cb.js"><link rel="prefetch" href="/assets/js/128.7465973e.js"><link rel="prefetch" href="/assets/js/129.f3d49d26.js"><link rel="prefetch" href="/assets/js/13.c98d76f0.js"><link rel="prefetch" href="/assets/js/130.7f786c09.js"><link rel="prefetch" href="/assets/js/131.c588a4e5.js"><link rel="prefetch" href="/assets/js/132.a9d8f9d7.js"><link rel="prefetch" href="/assets/js/133.40e52588.js"><link rel="prefetch" href="/assets/js/134.46e589a3.js"><link rel="prefetch" href="/assets/js/135.22363a46.js"><link rel="prefetch" href="/assets/js/136.6ed1697a.js"><link rel="prefetch" href="/assets/js/137.85561c69.js"><link rel="prefetch" href="/assets/js/138.99a04494.js"><link rel="prefetch" href="/assets/js/139.f0552c7a.js"><link rel="prefetch" href="/assets/js/14.c033f4de.js"><link rel="prefetch" href="/assets/js/140.4ec1e061.js"><link rel="prefetch" href="/assets/js/141.a9837bb8.js"><link rel="prefetch" href="/assets/js/142.0daf24d0.js"><link rel="prefetch" href="/assets/js/143.f9fc0d3f.js"><link rel="prefetch" href="/assets/js/144.755f8542.js"><link rel="prefetch" href="/assets/js/145.fd3d789b.js"><link rel="prefetch" href="/assets/js/146.c2c62b01.js"><link rel="prefetch" href="/assets/js/147.f946170d.js"><link rel="prefetch" href="/assets/js/148.7733f24d.js"><link rel="prefetch" href="/assets/js/149.5d54ce19.js"><link rel="prefetch" href="/assets/js/15.6900fe6f.js"><link rel="prefetch" href="/assets/js/150.09134583.js"><link rel="prefetch" href="/assets/js/151.7522945c.js"><link rel="prefetch" href="/assets/js/152.808bd1b6.js"><link rel="prefetch" href="/assets/js/153.0af3f06c.js"><link rel="prefetch" href="/assets/js/154.53831122.js"><link rel="prefetch" href="/assets/js/155.53e5bdc3.js"><link rel="prefetch" href="/assets/js/156.8923d841.js"><link rel="prefetch" href="/assets/js/157.04fb08da.js"><link rel="prefetch" href="/assets/js/158.0e6663e8.js"><link rel="prefetch" href="/assets/js/159.2670449b.js"><link rel="prefetch" href="/assets/js/16.5077eb29.js"><link rel="prefetch" href="/assets/js/160.3fc6588a.js"><link rel="prefetch" href="/assets/js/161.7875402e.js"><link rel="prefetch" href="/assets/js/162.541ec610.js"><link rel="prefetch" href="/assets/js/163.c17ccbc0.js"><link rel="prefetch" href="/assets/js/164.86fce3b4.js"><link rel="prefetch" href="/assets/js/165.2b9548d0.js"><link rel="prefetch" href="/assets/js/166.66a2805f.js"><link rel="prefetch" href="/assets/js/167.4de98e57.js"><link rel="prefetch" href="/assets/js/168.6f000eaa.js"><link rel="prefetch" href="/assets/js/169.cda36066.js"><link rel="prefetch" href="/assets/js/17.112268e5.js"><link rel="prefetch" href="/assets/js/170.3f1ae11a.js"><link rel="prefetch" href="/assets/js/171.ae67c120.js"><link rel="prefetch" href="/assets/js/172.6f2bed6e.js"><link rel="prefetch" href="/assets/js/173.2b8efaa1.js"><link rel="prefetch" href="/assets/js/174.01667775.js"><link rel="prefetch" href="/assets/js/175.b6b57c90.js"><link rel="prefetch" href="/assets/js/176.241f6966.js"><link rel="prefetch" href="/assets/js/177.20a02334.js"><link rel="prefetch" href="/assets/js/178.a338760c.js"><link rel="prefetch" href="/assets/js/179.d31d1033.js"><link rel="prefetch" href="/assets/js/18.b015dc58.js"><link rel="prefetch" href="/assets/js/180.5292fa26.js"><link rel="prefetch" href="/assets/js/181.d76d57b6.js"><link rel="prefetch" href="/assets/js/182.e53b7eee.js"><link rel="prefetch" href="/assets/js/183.dd36cb6c.js"><link rel="prefetch" href="/assets/js/184.8c5d1acd.js"><link rel="prefetch" href="/assets/js/185.0fa69241.js"><link rel="prefetch" href="/assets/js/186.a060dcfc.js"><link rel="prefetch" href="/assets/js/187.7c5dd016.js"><link rel="prefetch" href="/assets/js/188.e1d6eb59.js"><link rel="prefetch" href="/assets/js/189.d080da82.js"><link rel="prefetch" href="/assets/js/19.a730210d.js"><link rel="prefetch" href="/assets/js/190.5ea05bc2.js"><link rel="prefetch" href="/assets/js/191.ccce8c21.js"><link rel="prefetch" href="/assets/js/192.8919b9f4.js"><link rel="prefetch" href="/assets/js/193.53a2231c.js"><link rel="prefetch" href="/assets/js/194.7dc4768d.js"><link rel="prefetch" href="/assets/js/195.1f14c2d3.js"><link rel="prefetch" href="/assets/js/196.95e1de51.js"><link rel="prefetch" href="/assets/js/197.61f1490e.js"><link rel="prefetch" href="/assets/js/198.c16e311f.js"><link rel="prefetch" href="/assets/js/199.a0463af3.js"><link rel="prefetch" href="/assets/js/20.a01ca174.js"><link rel="prefetch" href="/assets/js/200.88a1d097.js"><link rel="prefetch" href="/assets/js/201.ccd16283.js"><link rel="prefetch" href="/assets/js/202.63c30104.js"><link rel="prefetch" href="/assets/js/203.75cacf3b.js"><link rel="prefetch" href="/assets/js/204.78d81202.js"><link rel="prefetch" href="/assets/js/205.428844a4.js"><link rel="prefetch" href="/assets/js/206.536ab8ea.js"><link rel="prefetch" href="/assets/js/207.1d6ea039.js"><link rel="prefetch" href="/assets/js/208.559fa16a.js"><link rel="prefetch" href="/assets/js/209.024c14ee.js"><link rel="prefetch" href="/assets/js/21.56e4f12e.js"><link rel="prefetch" href="/assets/js/210.b4e24295.js"><link rel="prefetch" href="/assets/js/211.59133109.js"><link rel="prefetch" href="/assets/js/212.2c11bc51.js"><link rel="prefetch" href="/assets/js/213.4124dac6.js"><link rel="prefetch" href="/assets/js/214.3fe2516e.js"><link rel="prefetch" href="/assets/js/215.aef02404.js"><link rel="prefetch" href="/assets/js/216.02f537aa.js"><link rel="prefetch" href="/assets/js/217.4fb1b7ef.js"><link rel="prefetch" href="/assets/js/218.2effa1a4.js"><link rel="prefetch" href="/assets/js/219.c1de57a8.js"><link rel="prefetch" href="/assets/js/22.fcddc1c6.js"><link rel="prefetch" href="/assets/js/220.b5062ce2.js"><link rel="prefetch" href="/assets/js/221.d10aa87c.js"><link rel="prefetch" href="/assets/js/222.174a73b7.js"><link rel="prefetch" href="/assets/js/223.6bd66640.js"><link rel="prefetch" href="/assets/js/224.60738e78.js"><link rel="prefetch" href="/assets/js/225.29e10b6a.js"><link rel="prefetch" href="/assets/js/226.41609457.js"><link rel="prefetch" href="/assets/js/227.5d2a1817.js"><link rel="prefetch" href="/assets/js/228.ae086e62.js"><link rel="prefetch" href="/assets/js/229.23dbfd01.js"><link rel="prefetch" href="/assets/js/23.c542ac54.js"><link rel="prefetch" href="/assets/js/230.846276a3.js"><link rel="prefetch" href="/assets/js/231.a85ab6e0.js"><link rel="prefetch" href="/assets/js/232.0b6e6b4c.js"><link rel="prefetch" href="/assets/js/233.6cb92776.js"><link rel="prefetch" href="/assets/js/234.cea1dee5.js"><link rel="prefetch" href="/assets/js/235.500e92ea.js"><link rel="prefetch" href="/assets/js/236.bbc42488.js"><link rel="prefetch" href="/assets/js/237.2a724798.js"><link rel="prefetch" href="/assets/js/238.4ab2349d.js"><link rel="prefetch" href="/assets/js/239.d0bfc9cf.js"><link rel="prefetch" href="/assets/js/24.b876b0b7.js"><link rel="prefetch" href="/assets/js/240.605bb0c5.js"><link rel="prefetch" href="/assets/js/241.9570c994.js"><link rel="prefetch" href="/assets/js/242.18d655b8.js"><link rel="prefetch" href="/assets/js/243.1001542c.js"><link rel="prefetch" href="/assets/js/244.b6b11929.js"><link rel="prefetch" href="/assets/js/245.80f35f7e.js"><link rel="prefetch" href="/assets/js/246.33b89f85.js"><link rel="prefetch" href="/assets/js/247.7b6887c5.js"><link rel="prefetch" href="/assets/js/248.63719a2c.js"><link rel="prefetch" href="/assets/js/249.67a27bcb.js"><link rel="prefetch" href="/assets/js/25.1dcefbee.js"><link rel="prefetch" href="/assets/js/250.b26d162c.js"><link rel="prefetch" href="/assets/js/251.c796b53a.js"><link rel="prefetch" href="/assets/js/252.1305b2c8.js"><link rel="prefetch" href="/assets/js/253.032816e3.js"><link rel="prefetch" href="/assets/js/254.a40ea038.js"><link rel="prefetch" href="/assets/js/255.f961cc57.js"><link rel="prefetch" href="/assets/js/256.db863c94.js"><link rel="prefetch" href="/assets/js/257.d4fbd9ba.js"><link rel="prefetch" href="/assets/js/258.e75fd178.js"><link rel="prefetch" href="/assets/js/259.86faea64.js"><link rel="prefetch" href="/assets/js/26.59e81884.js"><link rel="prefetch" href="/assets/js/260.5052982a.js"><link rel="prefetch" href="/assets/js/261.e5150bda.js"><link rel="prefetch" href="/assets/js/262.d38b609d.js"><link rel="prefetch" href="/assets/js/263.6e33b2d1.js"><link rel="prefetch" href="/assets/js/264.bbb4378b.js"><link rel="prefetch" href="/assets/js/265.c10f1cb4.js"><link rel="prefetch" href="/assets/js/266.da1848ad.js"><link rel="prefetch" href="/assets/js/267.669cad05.js"><link rel="prefetch" href="/assets/js/268.849e9b54.js"><link rel="prefetch" href="/assets/js/269.db147d70.js"><link rel="prefetch" href="/assets/js/27.c6d3d68b.js"><link rel="prefetch" href="/assets/js/270.d7a9657a.js"><link rel="prefetch" href="/assets/js/271.7780769c.js"><link rel="prefetch" href="/assets/js/272.87997591.js"><link rel="prefetch" href="/assets/js/273.f97c10b8.js"><link rel="prefetch" href="/assets/js/274.21a985e4.js"><link rel="prefetch" href="/assets/js/275.26455192.js"><link rel="prefetch" href="/assets/js/276.a7c80ed1.js"><link rel="prefetch" href="/assets/js/277.c3387517.js"><link rel="prefetch" href="/assets/js/278.b8efb02b.js"><link rel="prefetch" href="/assets/js/279.28947d1f.js"><link rel="prefetch" href="/assets/js/28.6f255334.js"><link rel="prefetch" href="/assets/js/280.9d7368cd.js"><link rel="prefetch" href="/assets/js/281.536ed57f.js"><link rel="prefetch" href="/assets/js/282.bc9c2104.js"><link rel="prefetch" href="/assets/js/283.be87340c.js"><link rel="prefetch" href="/assets/js/284.85f91dd9.js"><link rel="prefetch" href="/assets/js/285.c997d364.js"><link rel="prefetch" href="/assets/js/29.ff17d212.js"><link rel="prefetch" href="/assets/js/3.939eb1e6.js"><link rel="prefetch" href="/assets/js/30.de8e75fd.js"><link rel="prefetch" href="/assets/js/31.2237e84f.js"><link rel="prefetch" href="/assets/js/32.24ea6ffd.js"><link rel="prefetch" href="/assets/js/33.24c84eee.js"><link rel="prefetch" href="/assets/js/34.7d7c5d30.js"><link rel="prefetch" href="/assets/js/35.e122dd64.js"><link rel="prefetch" href="/assets/js/36.62df0b93.js"><link rel="prefetch" href="/assets/js/37.df57cb81.js"><link rel="prefetch" href="/assets/js/38.3ec5fc5b.js"><link rel="prefetch" href="/assets/js/39.390a3693.js"><link rel="prefetch" href="/assets/js/4.61dbd51c.js"><link rel="prefetch" href="/assets/js/40.55d80750.js"><link rel="prefetch" href="/assets/js/41.2ab0a6ab.js"><link rel="prefetch" href="/assets/js/42.64bcd0f8.js"><link rel="prefetch" href="/assets/js/43.8b758d29.js"><link rel="prefetch" href="/assets/js/45.215f31f9.js"><link rel="prefetch" href="/assets/js/46.2841afe2.js"><link rel="prefetch" href="/assets/js/47.f898542e.js"><link rel="prefetch" href="/assets/js/48.d71a0437.js"><link rel="prefetch" href="/assets/js/49.09e4d0dc.js"><link rel="prefetch" href="/assets/js/5.8404b813.js"><link rel="prefetch" href="/assets/js/50.ca870680.js"><link rel="prefetch" href="/assets/js/51.76cb8363.js"><link rel="prefetch" href="/assets/js/52.7746a702.js"><link rel="prefetch" href="/assets/js/53.92e1e16d.js"><link rel="prefetch" href="/assets/js/54.565d805f.js"><link rel="prefetch" href="/assets/js/55.cd788d8f.js"><link rel="prefetch" href="/assets/js/56.8f7bf723.js"><link rel="prefetch" href="/assets/js/57.91a0d761.js"><link rel="prefetch" href="/assets/js/58.f642e24a.js"><link rel="prefetch" href="/assets/js/59.2a8e3be6.js"><link rel="prefetch" href="/assets/js/6.9c81633d.js"><link rel="prefetch" href="/assets/js/60.c832cb65.js"><link rel="prefetch" href="/assets/js/61.fe244e14.js"><link rel="prefetch" href="/assets/js/62.a6df731e.js"><link rel="prefetch" href="/assets/js/63.2d9337d6.js"><link rel="prefetch" href="/assets/js/64.175c6cf8.js"><link rel="prefetch" href="/assets/js/65.71d399f4.js"><link rel="prefetch" href="/assets/js/66.c2ff4239.js"><link rel="prefetch" href="/assets/js/67.2520b141.js"><link rel="prefetch" href="/assets/js/68.5e59ea8f.js"><link rel="prefetch" href="/assets/js/69.ef86b576.js"><link rel="prefetch" href="/assets/js/7.0dcde973.js"><link rel="prefetch" href="/assets/js/70.b6a38514.js"><link rel="prefetch" href="/assets/js/71.6891db67.js"><link rel="prefetch" href="/assets/js/72.875d6b6d.js"><link rel="prefetch" href="/assets/js/73.7b2a501e.js"><link rel="prefetch" href="/assets/js/74.58bab29f.js"><link rel="prefetch" href="/assets/js/75.07cbc52d.js"><link rel="prefetch" href="/assets/js/76.4abced12.js"><link rel="prefetch" href="/assets/js/77.7d6f96ed.js"><link rel="prefetch" href="/assets/js/78.bcf6d0aa.js"><link rel="prefetch" href="/assets/js/79.518f153c.js"><link rel="prefetch" href="/assets/js/80.28a5affe.js"><link rel="prefetch" href="/assets/js/81.b454a9d9.js"><link rel="prefetch" href="/assets/js/82.d1cece4c.js"><link rel="prefetch" href="/assets/js/83.206656f4.js"><link rel="prefetch" href="/assets/js/84.f148ca2a.js"><link rel="prefetch" href="/assets/js/85.49862eae.js"><link rel="prefetch" href="/assets/js/86.1be96c00.js"><link rel="prefetch" href="/assets/js/87.29271ed2.js"><link rel="prefetch" href="/assets/js/88.f0267ae8.js"><link rel="prefetch" href="/assets/js/89.74e42f1e.js"><link rel="prefetch" href="/assets/js/90.c2d94a52.js"><link rel="prefetch" href="/assets/js/91.8567aa93.js"><link rel="prefetch" href="/assets/js/92.44b8dd08.js"><link rel="prefetch" href="/assets/js/93.4d546387.js"><link rel="prefetch" href="/assets/js/94.6d4c5937.js"><link rel="prefetch" href="/assets/js/95.67ba4aea.js"><link rel="prefetch" href="/assets/js/96.5137f1ee.js"><link rel="prefetch" href="/assets/js/97.5861f7e7.js"><link rel="prefetch" href="/assets/js/98.80a7594c.js"><link rel="prefetch" href="/assets/js/99.4236959e.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.6fed1ae2.js">
    <link rel="stylesheet" href="/assets/css/0.styles.c5e7512f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">GoldNotes</span></a> <div class="links"><nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="计算机视觉" class="dropdown-title"><span class="title">计算机视觉</span> <span class="arrow down"></span></button> <button type="button" aria-label="计算机视觉" class="mobile-dropdown-title"><span class="title">计算机视觉</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/cv/dip/" class="nav-link">
  学习图像处理
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection/" class="nav-link">
  学习目标检测
</a></li><li class="dropdown-item"><!----> <a href="/cv/segmentation/" class="nav-link">
  学习语义分割
</a></li><li class="dropdown-item"><!----> <a href="/cv/ocr/" class="nav-link">
  学习OCR
</a></li><li class="dropdown-item"><!----> <a href="/cv/human-pose/" class="nav-link">
  学习姿态估计
</a></li><li class="dropdown-item"><!----> <a href="/cv/gan/" class="nav-link">
  学习生成对抗网络
</a></li><li class="dropdown-item"><!----> <a href="/cv/datasets/" class="nav-link">
  学习开源数据
</a></li><li class="dropdown-item"><!----> <a href="/cv/tracking/" class="nav-link">
  学习目标追踪
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection3d/" class="nav-link">
  学习3D目标检测
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法框架" class="dropdown-title"><span class="title">算法框架</span> <span class="arrow down"></span></button> <button type="button" aria-label="算法框架" class="mobile-dropdown-title"><span class="title">算法框架</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ai/opencv/" class="nav-link">
  学习OpenCV
</a></li><li class="dropdown-item"><!----> <a href="/ai/torch/" class="nav-link router-link-active">
  学习pytorch
</a></li><li class="dropdown-item"><!----> <a href="/ai/cuda/" class="nav-link">
  学习CUDA
</a></li><li class="dropdown-item"><!----> <a href="/ai/tensorflow/" class="nav-link">
  学习tensorflow
</a></li><li class="dropdown-item"><!----> <a href="/ai/onnx/" class="nav-link">
  学习ONNX
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="机器学习" class="dropdown-title"><span class="title">机器学习</span> <span class="arrow down"></span></button> <button type="button" aria-label="机器学习" class="mobile-dropdown-title"><span class="title">机器学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ml/gnn/" class="nav-link">
  学习图算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/singleclass/" class="nav-link">
  学习单分类算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/oneshot/" class="nav-link">
  学习小样本算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/common/" class="nav-link">
  学习常用算法
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="操作系统" class="dropdown-title"><span class="title">操作系统</span> <span class="arrow down"></span></button> <button type="button" aria-label="操作系统" class="mobile-dropdown-title"><span class="title">操作系统</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/system/" class="nav-link">
  学习操作系统
</a></li><li class="dropdown-item"><!----> <a href="/system/linux/" class="nav-link">
  学习linux
</a></li><li class="dropdown-item"><!----> <a href="/system/ros/" class="nav-link">
  学习ROS
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/langs/se/" class="nav-link">
  学习软件开发
</a></li><li class="dropdown-item"><!----> <a href="/langs/python/" class="nav-link">
  学习Python
</a></li><li class="dropdown-item"><!----> <a href="/langs/cpp/" class="nav-link">
  学习C++
</a></li><li class="dropdown-item"><!----> <a href="/langs/yaml/" class="nav-link">
  学习yaml
</a></li><li class="dropdown-item"><!----> <a href="/langs/sqlite/" class="nav-link">
  学习sql
</a></li><li class="dropdown-item"><!----> <a href="/langs/shell/" class="nav-link">
  学习shell
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="IT工具" class="dropdown-title"><span class="title">IT工具</span> <span class="arrow down"></span></button> <button type="button" aria-label="IT工具" class="mobile-dropdown-title"><span class="title">IT工具</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tools/git/" class="nav-link">
  学习GIT
</a></li><li class="dropdown-item"><!----> <a href="/tools/docker/" class="nav-link">
  学习Docker
</a></li><li class="dropdown-item"><!----> <a href="/tools/gimp/" class="nav-link">
  学习GIMP
</a></li><li class="dropdown-item"><!----> <a href="/tools/vscode/" class="nav-link">
  学习VSCode
</a></li><li class="dropdown-item"><!----> <a href="/tools/hexo/" class="nav-link">
  学习hexo
</a></li><li class="dropdown-item"><!----> <a href="/tools/others/" class="nav-link">
  学习常用工具
</a></li><li class="dropdown-item"><!----> <a href="/tools/leetcodes/" class="nav-link">
  基础算法刷题
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数学知识" class="dropdown-title"><span class="title">数学知识</span> <span class="arrow down"></span></button> <button type="button" aria-label="数学知识" class="mobile-dropdown-title"><span class="title">数学知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/math/statistics/" class="nav-link">
  学习概率统计
</a></li><li class="dropdown-item"><!----> <a href="/math/linear-algebra/" class="nav-link">
  学习线性代数
</a></li><li class="dropdown-item"><!----> <a href="/math/calculus/" class="nav-link">
  学习高等数学
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="理财基础" class="dropdown-title"><span class="title">理财基础</span> <span class="arrow down"></span></button> <button type="button" aria-label="理财基础" class="mobile-dropdown-title"><span class="title">理财基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/finance/evaluate.html" class="nav-link">
  评测指标
</a></li></ul></div></div> <!----></nav> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="计算机视觉" class="dropdown-title"><span class="title">计算机视觉</span> <span class="arrow down"></span></button> <button type="button" aria-label="计算机视觉" class="mobile-dropdown-title"><span class="title">计算机视觉</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/cv/dip/" class="nav-link">
  学习图像处理
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection/" class="nav-link">
  学习目标检测
</a></li><li class="dropdown-item"><!----> <a href="/cv/segmentation/" class="nav-link">
  学习语义分割
</a></li><li class="dropdown-item"><!----> <a href="/cv/ocr/" class="nav-link">
  学习OCR
</a></li><li class="dropdown-item"><!----> <a href="/cv/human-pose/" class="nav-link">
  学习姿态估计
</a></li><li class="dropdown-item"><!----> <a href="/cv/gan/" class="nav-link">
  学习生成对抗网络
</a></li><li class="dropdown-item"><!----> <a href="/cv/datasets/" class="nav-link">
  学习开源数据
</a></li><li class="dropdown-item"><!----> <a href="/cv/tracking/" class="nav-link">
  学习目标追踪
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection3d/" class="nav-link">
  学习3D目标检测
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法框架" class="dropdown-title"><span class="title">算法框架</span> <span class="arrow down"></span></button> <button type="button" aria-label="算法框架" class="mobile-dropdown-title"><span class="title">算法框架</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ai/opencv/" class="nav-link">
  学习OpenCV
</a></li><li class="dropdown-item"><!----> <a href="/ai/torch/" class="nav-link router-link-active">
  学习pytorch
</a></li><li class="dropdown-item"><!----> <a href="/ai/cuda/" class="nav-link">
  学习CUDA
</a></li><li class="dropdown-item"><!----> <a href="/ai/tensorflow/" class="nav-link">
  学习tensorflow
</a></li><li class="dropdown-item"><!----> <a href="/ai/onnx/" class="nav-link">
  学习ONNX
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="机器学习" class="dropdown-title"><span class="title">机器学习</span> <span class="arrow down"></span></button> <button type="button" aria-label="机器学习" class="mobile-dropdown-title"><span class="title">机器学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ml/gnn/" class="nav-link">
  学习图算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/singleclass/" class="nav-link">
  学习单分类算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/oneshot/" class="nav-link">
  学习小样本算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/common/" class="nav-link">
  学习常用算法
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="操作系统" class="dropdown-title"><span class="title">操作系统</span> <span class="arrow down"></span></button> <button type="button" aria-label="操作系统" class="mobile-dropdown-title"><span class="title">操作系统</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/system/" class="nav-link">
  学习操作系统
</a></li><li class="dropdown-item"><!----> <a href="/system/linux/" class="nav-link">
  学习linux
</a></li><li class="dropdown-item"><!----> <a href="/system/ros/" class="nav-link">
  学习ROS
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/langs/se/" class="nav-link">
  学习软件开发
</a></li><li class="dropdown-item"><!----> <a href="/langs/python/" class="nav-link">
  学习Python
</a></li><li class="dropdown-item"><!----> <a href="/langs/cpp/" class="nav-link">
  学习C++
</a></li><li class="dropdown-item"><!----> <a href="/langs/yaml/" class="nav-link">
  学习yaml
</a></li><li class="dropdown-item"><!----> <a href="/langs/sqlite/" class="nav-link">
  学习sql
</a></li><li class="dropdown-item"><!----> <a href="/langs/shell/" class="nav-link">
  学习shell
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="IT工具" class="dropdown-title"><span class="title">IT工具</span> <span class="arrow down"></span></button> <button type="button" aria-label="IT工具" class="mobile-dropdown-title"><span class="title">IT工具</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tools/git/" class="nav-link">
  学习GIT
</a></li><li class="dropdown-item"><!----> <a href="/tools/docker/" class="nav-link">
  学习Docker
</a></li><li class="dropdown-item"><!----> <a href="/tools/gimp/" class="nav-link">
  学习GIMP
</a></li><li class="dropdown-item"><!----> <a href="/tools/vscode/" class="nav-link">
  学习VSCode
</a></li><li class="dropdown-item"><!----> <a href="/tools/hexo/" class="nav-link">
  学习hexo
</a></li><li class="dropdown-item"><!----> <a href="/tools/others/" class="nav-link">
  学习常用工具
</a></li><li class="dropdown-item"><!----> <a href="/tools/leetcodes/" class="nav-link">
  基础算法刷题
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数学知识" class="dropdown-title"><span class="title">数学知识</span> <span class="arrow down"></span></button> <button type="button" aria-label="数学知识" class="mobile-dropdown-title"><span class="title">数学知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/math/statistics/" class="nav-link">
  学习概率统计
</a></li><li class="dropdown-item"><!----> <a href="/math/linear-algebra/" class="nav-link">
  学习线性代数
</a></li><li class="dropdown-item"><!----> <a href="/math/calculus/" class="nav-link">
  学习高等数学
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="理财基础" class="dropdown-title"><span class="title">理财基础</span> <span class="arrow down"></span></button> <button type="button" aria-label="理财基础" class="mobile-dropdown-title"><span class="title">理财基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/finance/evaluate.html" class="nav-link">
  评测指标
</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>学习pytorch</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ai/torch/" aria-current="page" class="sidebar-link">Introduction About Torch Gradient</a></li><li><a href="/ai/torch/interpolate.html" class="sidebar-link">TORCH.NN.FUNCTIONAL.INTERPOLATE使用说明</a></li><li><a href="/ai/torch/batchnorm.html" class="sidebar-link">详解Pytorch中的BatchNorm模块</a></li><li><a href="/ai/torch/sum.html" class="sidebar-link">torch.sum API</a></li><li><a href="/ai/torch/grid_sample.html" class="sidebar-link">pytorch中的grid_sample</a></li><li><a href="/ai/torch/dpp.html" aria-current="page" class="active sidebar-link">Pytorch的单机多GPU训练</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/ai/torch/dpp.html#_1-多gpu训练介绍" class="sidebar-link">1)多GPU训练介绍</a></li><li class="sidebar-sub-header"><a href="/ai/torch/dpp.html#_2-pytorch中使用单机多gpu训练" class="sidebar-link">2)pytorch中使用单机多GPU训练</a></li><li class="sidebar-sub-header"><a href="/ai/torch/dpp.html#_3-使用distributeddataparallel训练模型的一个简单实例" class="sidebar-link">3)使用DistributedDataParallel训练模型的一个简单实例</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="pytorch的单机多gpu训练"><a href="#pytorch的单机多gpu训练" class="header-anchor">#</a> Pytorch的单机多GPU训练</h1> <h2 id="_1-多gpu训练介绍"><a href="#_1-多gpu训练介绍" class="header-anchor">#</a> 1)多GPU训练介绍</h2> <p>当我们使用的模型过大，训练数据比较多的时候往往需要在多个<code>GPU</code>上训练。<strong>使用多<code>GPU</code>训练时有两种方式，一种叫<code>ModelParallelism</code>，一种是<code>DataParallelism</code></strong>。</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/mgpu1.png" alt=""></p> <p><code>ModelParallelism</code>方式，是在模型比较大导致一张显卡放不下的时候，将模型拆分然后分别放到不同的显卡上，将同一份数据分别输入进行模型训练。这种对模型结构各模块之间有联系时很不友好，有可能都不支持拆分。因此，应用更广泛的是<code>DataParallelism</code>的方式。</p> <p><code>DataParallelism</code>方式，是将相同的模型拷贝到不同的显卡上，然后将数据平均划分后输入到相应显卡上进行计算，然后根据计算结果更新模型的参数。</p> <p><code>DataParallelism</code>方式<strong>更新模型参数</strong>时，因为每个显卡上都有一个完整的模型，其可以单独根据一个显卡的运算结果更新参数，即<strong>异步更新</strong>，也可以将各个显卡的运算结果汇总后再根据总的运算结果一次性更新模型参数，即<strong>同步更新</strong>。因此，使用<code>DataParallelism</code>模型参数的更新有两种选择方式，不过值得注意的是不同显卡上的模型参数是共享的，也就是虽然不同显卡上都有完整的模型，但模型参数用的是同一份，都是相同的。 所以在模型初始化的时候就要给不同显卡上的模型初始化相同的权重值。根据两种权重更新策略的区别，可以发现，对于单个显卡上<code>batch_size</code>本身就比较大的情况，可以使用异步更新，这样不需要显卡之间运算同步，可以提升训练速度；而对于<code>batch_size</code>比较小的情况，根据<code>mini_batch</code>随机梯度下降算法的原理，最好选用<strong>同步更新</strong>的方式，保证学习效果。</p> <blockquote><p>图片引用自<a href="https://zhuanlan.zhihu.com/p/72939003" target="_blank" rel="noopener noreferrer">【分布式训练】单机多卡的正确打开方式（一）：理论基础<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br></p><div align="center"><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/mparam1.webp"><br><span style="color:gray;">参数同步更新</span><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/mparam2.webp"><br><span style="color:gray;">参数异步更新</span><div><p></p></div></div></blockquote> <p>使用多<code>GPU</code>训练时，还需要注意的是<strong>使用<code>BatchNormalization</code>的情况</strong>，对于<code>BN</code>层归一化时，是在单个显卡上计算，还是在不同的显卡之间做同步再计算，同样，对于<code>batch_size</code>比较大时建议使用异步运算，小时使用同步计算以保证模型学习的效果。</p> <h2 id="_2-pytorch中使用单机多gpu训练"><a href="#_2-pytorch中使用单机多gpu训练" class="header-anchor">#</a> 2)pytorch中使用单机多<code>GPU</code>训练</h2> <p>相对于<code>tensorflow</code>来说，<code>pytorch</code>中设置模型进行多<code>GPU</code>训练的方式就显的简单多了。在这里只介绍现在<code>pytorch</code>中使用最多的多<code>GPU</code>训练方式即使用<code>DistributedDataParallel</code>类。</p> <h3 id="distributeddataparallel-ddp-相关变量及含义"><a href="#distributeddataparallel-ddp-相关变量及含义" class="header-anchor">#</a> <code>DistributedDataParallel</code>(DDP)相关变量及含义</h3> <p><code>DDP</code>支持在多个机器中进行模型训练，其中每个机器被称之为节点<code>Node</code>，每个机器上有可能有多个<code>GPU</code>，为了不受<code>GIL</code>的限制，<code>DDP</code>会针对每个<code>GPU</code>启动一个进程进行训练，每个进程在对应机器上的编号使用环境变量<code>LOCAL_RANK</code>进行标识。</p> <p>一次训练，在所有<code>Node</code>上启动的训练进程总和使用<code>WORLD_SIZE</code>来统计。而在分布在所有<code>Node</code>的上某个进程在全局所有进程中的序号使用环境变量<code>RANK</code>进行记录。</p> <p>介绍到这<code>DDP</code>的整体原理和使用的变量就很清楚了，</p> <div align="center"><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/mgpu4.png"><br><span style="color:gray;">DDP</span></div> <p>参考上图，是假设有<code>3</code>台机器，每台机器上有<code>2</code>个<code>GPU</code>的情况。值的注意的是<code>master_address</code>和<code>master_port</code>上的参数，这两个参数是告诉其他进程主进程(<code>RANK=0</code>的进程）的端口号和<code>IP</code>地址，以便于其与主进程之间进行通信，包括数据交换，同步等。</p> <p>下面几部分，就分别对<code>pytorch</code>模型实现单机多<code>GPU</code>训练要进行哪些设置分别进行介绍。</p> <h3 id="a-初始化"><a href="#a-初始化" class="header-anchor">#</a> a)初始化</h3> <p>在编写多<code>GPU</code>训练的代码时，需要先对环境进行初始化，需要调用<code>init_process_group</code>来初始化默认的分布式进程组(<code>default distributed process group</code>)和分布式包(<code>distributed package</code>)。使用的是<code>pytorch</code>的<code>torch.distributed.init_process_group</code>方法。</p> <p>该方法原型：</p> <div class="language-python extra-class"><pre class="language-python"><code>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> \
                                     init_method<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> \
                                     timeout<span class="token operator">=</span>datetime<span class="token punctuation">.</span>timedelta<span class="token punctuation">(</span>seconds<span class="token operator">=</span><span class="token number">1800</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \
                                     world_size<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> \
                                     rank<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> \
                                     store<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> \
                                     group_name<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> \
                                     pg_options<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre></div><p>函数参数：</p> <ul><li><code>backend</code>: 参数类型为<code>str or Backend</code>，根据<code>pytorch</code>编译时的配置来选择，支持<code>mpi/gloo/nccl/ucc</code>，这个后端指的是多<code>GPU</code>之间进行通信的方式，根据不同类型的<code>GPU</code>进行选择，对于<code>NVIDIA</code>的<code>GPU</code>一般选择<code>nccl</code>，对于<code>Intel</code>的<code>GPU</code>一般选择<code>ucc</code>。</li> <li><code>init_method</code>: 参数类型为<code>str</code>，指定初始化方法，一般使用<code>env://</code>，表示使用环境变量<code>MASTER_ADDR</code>和<code>MASTER_PORT</code>来初始化。和<code>store</code>变量是互斥的。</li> <li><code>timeout</code>: 参数类型为<code>datetime.timedelta</code>，指定初始化超时时间，如果超时则抛出异常。</li> <li><code>world_size</code>: 参数类型为<code>int</code>，指定进程组的大小，如果为<code>-1</code>，则使用环境变量<code>WORLD_SIZE</code>来指定，定义<code>store</code>变量时必须指定<code>world_size</code>。</li> <li><code>rank</code>: 参数类型为<code>int</code>，指定当前进程在进程组中的排位，如果为<code>-1</code>，则使用环境变量<code>RANK</code>来指定，定义<code>store</code>变量时，必须指定<code>rank</code>。</li> <li><code>store</code>: 参数类型为<code>Store</code>，指定用于保存分布式训练状态的存储<code>Key/Value</code>对象,用于交换连接/地址信息，所有的进程都能访问，和<code>init_method</code>方法互斥。</li> <li><code>group_name</code>: 参数类型为<code>str</code>，指定进程组的名字，这个变量已经是<code>deprecated</code>了。</li> <li><code>pg_options</code>: 参数类型为<code>ProcessGroupOptions</code>，指定进程组的其他选项，如<code>allreduce_post_hook</code>等,目前仅对<code>nccl</code>后端支持<code>ProcessGroupNCCL.Options</code>选项。</li></ul> <p><strong>使用<code>torch.distributed.init_process_group</code>初始化进程组的两种方式</strong>：</p> <ul><li>指定<code>store/rank/world_size</code></li> <li>指定<code>init_method</code>，明确给出进程间在哪通过哪种协议发现其他进程并通信，此时<code>rank/world_size</code>是可选的</li></ul> <p><strong>初始化后，进程组可以通过<code>torch.distributed.get_world_size()</code>和<code>torch.distributed.get_rank()</code>来获取进程组大小和当前进程在进程组中的排位</strong>。</p> <p>所以最简单的初始化方式，只需要指定后端即可：</p> <div class="language-python extra-class"><pre class="language-python"><code>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>
</code></pre></div><p>每个进程的环境变量<code>RANK</code>是在启动时由<code>torchrun</code>命令行工具自动添加的，<code>WORLD_SIZE</code>是在<code>torchrun</code>启动时根据启动的进程数自动添加的。</p> <h3 id="b-数据准备"><a href="#b-数据准备" class="header-anchor">#</a> b)数据准备</h3> <p>在<code>pytorch</code>中，数据的准备是先实例化<code>torch.utils.data.Dataset</code>的数据类，然后再将其放入数据加载器<code>torch.utils.data.DataLoader</code>中，以控制加载数据的进程数<code>num_worker</code>、采样器<code>sampler</code>和<code>batch_size</code>大小等。</p> <p>在使用<code>DistributedDataParallel</code>实现训练时，在数据加载器中上需要使用两个采样器<code>sampler = DistributedSampler(data)</code>和<code>batch_sampler = torch.utils.data.BatchSampler(train_sampler, batch_size, drop_last=True)</code>来指定数据采样器，这样可以保证每个进程每个<code>batch</code>只处理属于自己的数据。</p> <p>这里一起来看下<code>DistributedSampler</code>和<code>BatchSampler</code>。</p> <p><strong><code>DDP</code>模式就是将数据均分到多个<code>GPU</code>上来优化算法，对于每个<code>GPU</code>该如何从总的训练数据中采样属于自己用的数据，这就需要一个采样策略，这正是<code>DistributedSampler</code>发挥的作用</strong>。</p> <div align="center"><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/mgpu5c.jpg"><br><span style="color:gray;">DistributedSampler</span></div> <p>如上图，假设有<code>11</code>个样本，<code>GPU</code>的数量为<code>2</code>，<code>DistributedSampler</code>的作用先是把数据打散，然后均分到每个<code>gpu</code>上，当数据不组时，会采用循环重复的策略来补满。</p> <p><code>torch.utils.data.BatchSampler</code>则是指定每个<code>batch</code>的样本数量，以及是否丢弃最后一个可能不足的<code>batch</code>。当设置<code>drop_last=True</code>时，会将最后不足一个<code>batch</code>的数据丢弃。</p> <div align="center"><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/mgpu6.jpg"><br><span style="color:gray;">BatchSampler</span></div> <p>上面介绍的过程是对于一轮数据训练时数据加载器的工作过程，对整个训练过程，为了保证学习的效果，需要在每个<code>epoch</code>设置采样器能重新打散数据，因此要在每一轮训练开始前调用<code>DistributedSampler</code>的<code>set_epoch</code>方法。</p> <div class="language-python extra-class"><pre class="language-python"><code>sampler <span class="token operator">=</span> DistributedSampler<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
batch_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>BatchSampler<span class="token punctuation">(</span>
        sampler<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataloader<span class="token punctuation">(</span>data_set<span class="token punctuation">,</span> batch_sampler<span class="token operator">=</span>train_batch_sampler<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre></div><h3 id="c-模型准备"><a href="#c-模型准备" class="header-anchor">#</a> c)模型准备</h3> <p>使用<code>DistributedDataParallel</code>进行模型训练时，需要将模型放在<code>DistributedDataParallel</code>类中，这样模型就可以在多<code>GPU</code>上并行计算。</p> <p>此外，还有一些需要注意的。</p> <p>在设置<code>device</code>时，要想指定使用的<code>GPU</code>需要设置环境变量<code>CUDA_VISIBLE_DEVICES=1,2</code>，在代码中对于模型，可以使用<code>model.to(device)来设置</code>，<code>device</code>从<code>LOCAL_RANK</code>中获取，当设置<code>CUDA_VISIBLE_DEVICES</code>时，<code>LOCAL_RANK</code>的<code>0</code>时从指定的<code>GPU</code>开始的，而不是硬件上的<code>GPU</code>序号，例如指定<code>CUDA_VISIBLE_DEVICES=1,2</code>时，<code>LOCAL_RANK=0</code>时对应的是<code>GPU1</code>，<code>LOCAL_RANK=1</code>时对应的是<code>GPU2</code>。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># in train.py</span>
<span class="token keyword">import</span> os
device <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'cuda:</span><span class="token interpolation"><span class="token punctuation">{</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span>LOCAL_RANK<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span>
</code></pre></div><p>执行，</p> <div class="language-python extra-class"><pre class="language-python"><code>CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span> torchrun <span class="token operator">-</span><span class="token operator">-</span>nnodes <span class="token number">1</span> <span class="token operator">-</span><span class="token operator">-</span>nproc_group_size <span class="token number">2</span> train<span class="token punctuation">.</span>py
</code></pre></div><p>加载模型后对于使用多<code>GPU</code>时还需注意的是参数初始化，要使用同一份权重值对模型进行初始化，否则在模型训练时，每个<code>GPU</code>上的模型参数就会不一样，从而导致训练效果不佳。一种方案是将主进程上的权重先保存下来，然后再加载到其他进程的模型上：</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>weights_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    checkpoint_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>tempfile<span class="token punctuation">.</span>gettempdir<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;initial_weights.pt&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>checkpoint_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>上面的代码的功能很明了，值得注意的是<code>dist.barrier()</code>语句，它表示等待所有进程都到达这个语句处，然后才进行下一步操作，确保所有进程都执行到这一步，然后才开始进行权重加载。</p> <p>当模型使用<code>BatchNormalization</code>时，除了需要将模型放入<code>DistributedDataParallel</code>类中，还需要使用<code>torch.nn.SyncBatchNorm.convert_sync_batchnorm</code>方法对模型上的<code>BN</code>层进行转化，这样模型训练时，每个<code>GPU</code>上的<code>BatchNormalization</code>层就会与其他<code>GPU</code>上的<code>BN</code>层进行同步更新。</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">.</span>convert_sync_batchnorm<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>DistributedDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'LOCAL_RANK'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>到这里，能够在多<code>GPU</code>上训练的模型就准备好了。下面再来看下模型训练时需要留意的地方。</p> <ul><li><strong>训练过程中平均损失值的计算</strong>。在单个进程中<code>loss</code>是在单个进程数据上计算的，为了记录训练过程，打印平均损失值时，要将所有进程上的<code>loss</code>值累加后除以进程组的大小，以得到平均损失值。</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">reduce_value</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    world_size <span class="token operator">=</span> get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> world_size <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>  <span class="token comment"># 单GPU的情况</span>
        <span class="token keyword">return</span> value

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        dist<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
        <span class="token keyword">if</span> average<span class="token punctuation">:</span>
            value <span class="token operator">/=</span> world_size

        <span class="token keyword">return</span> value

reduace_value<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre></div><p>注意上面代码中使用的<code>dist.all_reduce</code>函数，它用于进行数据同步，将数据从所有进程收集到主进程上，并将主进程上的数据广播到所有进程上，这样所有进程上的数据就相同了。</p> <ul><li><p>训练完一个<code>epoch</code>时，在每个进程中要使用<code>torch.cuda.synchronize(device)</code>，以确保使用当前设备的所有进程都计算完成。</p></li> <li><p>在训练过程中使用<code>DDP</code>模型，进程验证时，也需要使用<code>dist.all_reduce</code>来统计所有的运算结果：</p></li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> data_loader<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    sum_num <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 在进程0中打印验证进度</span>
    <span class="token keyword">if</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;RANK&quot;</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        data_loader <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>

    <span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
        pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        sum_num <span class="token operator">+=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 等待所有进程计算完毕</span>
    <span class="token keyword">if</span> device <span class="token operator">!=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>synchronize<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    sum_num <span class="token operator">=</span> dist<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>sum_num<span class="token punctuation">)</span>

    <span class="token keyword">return</span> sum_num<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="d-清理"><a href="#d-清理" class="header-anchor">#</a> d)清理</h3> <p>在训练代码的最后，定义完训练逻辑后，需要调用<code>torch.distributed.destroy_process_group</code>来关闭进程组，结束进程之间的通信。</p> <div class="language-python extra-class"><pre class="language-python"><code>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>destroy_process_group<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="e-运行"><a href="#e-运行" class="header-anchor">#</a> e)运行</h3> <p><code>pytorch DistributedDataParallel</code>多<code>GPU</code>训练任务启动的命令通常使用的是<code>python -m torch.distributed.launch</code>，在<code>torch1.9.0</code>版本后引入了<code>torchrun</code>命令，两者功能基本类似，python -m torch.distributed.launch 和 torchrun 在功能上是类似的。它们都是用于启动分布式训练的命令行工具，可以自动设置环境变量并启动训练脚本。<code>torchrun</code> 是 <code>PyTorch 1.9.0 版本引入的新命令，旨在为分布式训练提供更简洁和一致的接口。与</code>python -m torch.distributed.launch<code>相比，</code>torchrun<code>具有一些额外的功能和灵活性，例如支持不同的运行模式和分布式运行时后端。对于使用较新版本</code>PyTorch<code>的情况，建议使用</code>torchrun` 来保持一致性以使用其提供的新功能。</p> <p>关于<code>torchrun</code>和<code>python -m torch.distributed.launch</code>命令支持的选项可以使用<code>--help</code>来查看。</p> <div class="language-sh extra-class"><pre class="language-sh"><code>torchrun <span class="token parameter variable">--nnodes</span> <span class="token number">1</span> <span class="token parameter variable">--nproc_per_node</span> <span class="token number">2</span> train.py train_args

python <span class="token parameter variable">-m</span> torch.distributed.launch <span class="token parameter variable">--nnodes</span> <span class="token number">1</span> <span class="token parameter variable">--nproc_per_node</span> train.py train_args
</code></pre></div><p>更底层的方法可以使用<code>torch.multiprocessing.spawn</code>函数来启动训练，它需要传递一个训练函数和进程数量作为参数。</p> <h2 id="_3-使用distributeddataparallel训练模型的一个简单实例"><a href="#_3-使用distributeddataparallel训练模型的一个简单实例" class="header-anchor">#</a> 3)使用<code>DistributedDataParallel</code>训练模型的一个简单实例</h2> <div class="language-python extra-class"><pre class="language-python"><code>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> os
<span class="token keyword">import</span> math
<span class="token keyword">import</span> tqdm
<span class="token keyword">import</span> sys

batch_size<span class="token operator">=</span><span class="token number">256</span>
epoches <span class="token operator">=</span> <span class="token number">100</span>
num_classes <span class="token operator">=</span> <span class="token number">10</span>

torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>

transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                  std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
train_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/cifar10&quot;</span><span class="token punctuation">,</span>
                                             train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                             download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                             transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/cifar10&quot;</span><span class="token punctuation">,</span>
                                           train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                           download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                           transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
num_classes <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>val_dataset<span class="token punctuation">.</span>classes<span class="token punctuation">)</span>

train_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>DistributedSampler<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>
val_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>DistributedSampler<span class="token punctuation">(</span>val_dataset<span class="token punctuation">)</span>
train_batch_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>BatchSampler<span class="token punctuation">(</span>train_sampler<span class="token punctuation">,</span> 
                                                    batch_size<span class="token punctuation">,</span> 
                                                    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                                               batch_sampler<span class="token operator">=</span>train_batch_sampler<span class="token punctuation">,</span>
                                               pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                               num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
val_dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span>
                                             batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                             sampler<span class="token operator">=</span>val_sampler<span class="token punctuation">,</span>
                                             pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                             num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

device <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'cuda:</span><span class="token interpolation"><span class="token punctuation">{</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

m <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>mobilenet_v3_small<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> 
                                          num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">)</span>
ckpt_path <span class="token operator">=</span> <span class="token string">&quot;/tmp/init_weight.pt&quot;</span>
<span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>m<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ckpt_path<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
m<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
m <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">.</span>convert_sync_batchnorm<span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
m <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>DistributedDataParallel<span class="token punctuation">(</span>m<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

params <span class="token operator">=</span> <span class="token punctuation">[</span> param <span class="token keyword">for</span> param <span class="token keyword">in</span> m<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad <span class="token punctuation">]</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span>params<span class="token punctuation">,</span>
                            lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>
                            momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>
                            weight_decay<span class="token operator">=</span><span class="token number">0.005</span><span class="token punctuation">)</span>
lr_func <span class="token operator">=</span> <span class="token keyword">lambda</span> x <span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> math<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x <span class="token operator">*</span> math<span class="token punctuation">.</span>pi <span class="token operator">/</span> epoches<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.1</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
                                              lr_lambda<span class="token operator">=</span>lr_func<span class="token punctuation">)</span>
loss_func <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
    m<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    avg_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    right_pred_num <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    best_acc <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        pbar <span class="token operator">=</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        pbar <span class="token operator">=</span> train_dataloader
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>image<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>pbar<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image <span class="token operator">=</span> image<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        pred <span class="token operator">=</span> m<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
        avg_loss <span class="token operator">=</span> <span class="token punctuation">(</span>avg_loss <span class="token operator">*</span> i <span class="token operator">+</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            pbar<span class="token punctuation">.</span>desc  <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;[epoch: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string">] step: </span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">, learning_rate: </span><span class="token interpolation"><span class="token punctuation">{</span>scheduler<span class="token punctuation">.</span>get_last_lr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> average loss: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">round</span><span class="token punctuation">(</span>avg_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span>
        <span class="token keyword">assert</span> torch<span class="token punctuation">.</span>isfinite<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;Nan Loss, Training End.&quot;</span></span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>synchronize<span class="token punctuation">(</span>device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    m<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            pbar <span class="token operator">=</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>val_dataloader<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            pbar <span class="token operator">=</span> val_dataloader
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>image<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>pbar<span class="token punctuation">)</span><span class="token punctuation">:</span>
            image <span class="token operator">=</span> image<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            pred <span class="token operator">=</span> m<span class="token punctuation">(</span>image<span class="token punctuation">)</span>            
            pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            right_pred_num <span class="token operator">+=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>synchronize<span class="token punctuation">(</span>device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>right_pred_num<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            acc <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>right_pred_num<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>val_dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Val Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>acc<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>
                best_acc <span class="token operator">=</span> acc
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;New Best Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>acc<span class="token punctuation">}</span></span><span class="token string">, Model Saved: best.pt&quot;</span></span><span class="token punctuation">)</span>
                torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>m<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;best.pt&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># CUDA_VISIBLE_DEVICES=3,4 torchrun -nnodes 1 --nproc_per_node 2 train.py</span>

<span class="token comment"># [epoch: 31] step: 23, learning_rate: [0.0007911220577405485] average loss: 3.66: </span>
<span class="token comment"># 100%|██████████████████████████████████████████████| 5/5 [00:01&lt;00:00,  3.01it/s]</span>
<span class="token comment"># Val Accuracy: 0.239</span>
<span class="token comment"># New Best Accuracy: 0.239, Model Saved: best.pt</span>
<span class="token comment"># [epoch: 32] step: 23, learning_rate: [0.0007790686370876671] average loss: 3.635:</span>
<span class="token comment"># 100%|██████████████████████████████████████████████| 5/5 [00:01&lt;00:00,  3.18it/s]</span>
<span class="token comment"># Val Accuracy: 0.247</span>
<span class="token comment"># New Best Accuracy: 0.247, Model Saved: best.pt</span>
</code></pre></div><p>代码也可从‵gitee`仓库中下载<a href="https://gitee.com/lx_r/object_detection_task/blob/main/cv_examples/torch_tutorials/ddp_train.py" target="_blank" rel="noopener noreferrer">https://gitee.com/lx_r/object_detection_task<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <div class="adswrapper"><!----> <div style="display:none;"></div> <ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-8685746128991385" data-ad-slot="2974191661" data-ad-test="" data-ad-region="" class="adsbygoogle" style="display:block;"></ins> <!----> <div style="display:none;"> (adsbygoogle = window.adsbygoogle || []).push({}); </div></div> <blockquote><p><a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/train_multi_GPU" target="_blank" rel="noopener noreferrer">1.https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/train_multi_GPU<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://www.bilibili.com/video/BV1yt4y1e7sZ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=e75f432df49764db96371bce27ab9fd5" target="_blank" rel="noopener noreferrer">2.pytorch多GPU并行训练教程<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://zhuanlan.zhihu.com/p/178402798" target="_blank" rel="noopener noreferrer">3.https://zhuanlan.zhihu.com/p/178402798<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://pytorch.org/tutorials/beginner/ddp_series_multigpu.html?highlight=multi" target="_blank" rel="noopener noreferrer">4.https://pytorch.org/tutorials/beginner/ddp_series_multigpu.html?highlight=multi<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://pytorch.org/tutorials/beginner/ddp_series_theory.html#why-you-should-prefer-ddp-over-dataparallel-dp" target="_blank" rel="noopener noreferrer">5.https://pytorch.org/tutorials/beginner/ddp_series_theory.html#why-you-should-prefer-ddp-over-dataparallel-dp<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://medium.com/red-buffer/getting-started-with-pytorch-distributed-54ae933bb9f0" target="_blank" rel="noopener noreferrer">6.https://medium.com/red-buffer/getting-started-with-pytorch-distributed-54ae933bb9f0<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/ai/torch/grid_sample.html" class="prev">
        pytorch中的grid_sample
      </a></span> <!----></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.4fb1e7ac.js" defer></script><script src="/assets/js/2.441eb26f.js" defer></script><script src="/assets/js/1.1a1c696e.js" defer></script><script src="/assets/js/44.01f440d3.js" defer></script>
  </body>
</html>
