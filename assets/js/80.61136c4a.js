(window.webpackJsonp=window.webpackJsonp||[]).push([[80],{340:function(t,a,e){"use strict";e.r(a);var s=e(17),r=function(t){t.options.__data__block__={mermaid_382ee204:"graph TD\na(noise)--\x3eb[Generator]--\x3ec(generated_images)\nc--\x3ed[Discriminator]--\x3ee(fake_output)\nf(image)---\x3eh[Discriminator]---\x3eg(real_output)\nsubgraph generated_loss \nsg1(ones_like_fake_output)--\x3e sg2[cross_entropy]\ne--\x3esg2\nsg2--\x3esg(generated_loss) \nend\nsubgraph discriminator_loss \nds1(ones_like_real_output)--\x3e ds2[cross_entropy_real_loss]\ng--\x3eds2\nds4(zeros_like_fake_output)--\x3e ds3[cross_entropy_fake_loss]\ne--\x3eds3 \nds[discriminator_loss] \nds2--\x3eds \nds3--\x3eds\nend"}},n=Object(s.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"生成对抗网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#生成对抗网络"}},[t._v("#")]),t._v(" 生成对抗网络")]),t._v(" "),a("h2",{attrs:{id:"_1-简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-简介"}},[t._v("#")]),t._v(" 1.简介")]),t._v(" "),a("p",[t._v("生成对抗网络Generative Adversarial Networks是法国蒙特利尔大学发表在"),a("code",[t._v("2014")]),t._v("年"),a("code",[t._v("NIPS")]),t._v("上的文章，提出了非常有意思的生成对抗网络。关于生成模型的介绍可以参考"),a("code",[t._v("MIT")]),t._v("的"),a("a",{attrs:{href:"http://introtodeeplearning.com/",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("DeepLearning")]),t._v("课程"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"_2-背景"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-背景"}},[t._v("#")]),t._v(" 2.背景")]),t._v(" "),a("h3",{attrs:{id:"_2-1生成模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1生成模型"}},[t._v("#")]),t._v(" 2.1生成模型")]),t._v(" "),a("p",[t._v("生成模型是这样的模型，其从一个数据分布中采样一部分点作为输入，然后训练模型来表征训练数据分布。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/ggmodel.jpg",alt:""}})]),t._v(" "),a("p",[t._v("使用生成模型的优点有：")]),t._v(" "),a("ul",[a("li",[t._v("1.能够去除数据中的偏置，找到数据的公共特征")]),t._v(" "),a("li",[t._v("2.当出现新的情况时可以做异常检测,处理未出现的情况")])]),t._v(" "),a("p",[t._v("常见的生成模型有自编码器"),a("code",[t._v("AutoEncoder")]),t._v("和生成对抗网络"),a("code",[t._v("GANs")]),t._v("，这两种模型，一般输入是图像，输出也是图像，网络本身包含了下采样和上采样的过程，似乎把模型变量隐藏了，因此也称为隐变量模型"),a("code",[t._v("Latent Variable Models")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/g2latentModel.jpg",alt:""}})]),t._v(" "),a("h3",{attrs:{id:"_2-2自编码器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2自编码器"}},[t._v("#")]),t._v(" 2.2自编码器")]),t._v(" "),a("p",[t._v("自编码器是通过下采样的编码器和上采样解码器来训练模型，使得对于输入图像得到与原图像大小相同的图像，然后最小化重建误差，来学习训练数据中的隐藏公共特征。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/g3ae.jpg",alt:""}})]),t._v(" "),a("h3",{attrs:{id:"_2-3变分自编码器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3变分自编码器"}},[t._v("#")]),t._v(" 2.3变分自编码器")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/gvae.jpg",alt:""}})]),t._v(" "),a("p",[t._v("变分自编码器（Variational auto-encoder，VAE）对每一个样本"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:"MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"X"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"k"}})],1)],1)],1)],1)],1),t._v("匹配一个高斯分布,隐变量Z就是从高斯分布中采样得到的。VAE让每个高斯分布尽可能地趋于标准高斯分布"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:"MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"N"}})],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"0"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，拟合过程中的误差损失则是采用KL散度作为计算。")],1),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/gvae_detail.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"_3-生成对抗网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-生成对抗网络"}},[t._v("#")]),t._v(" 3.生成对抗网络")]),t._v(" "),a("p",[t._v("生成对抗网络有两部分组成，一个生成器和判别器，生成器用来将一个随机的输入生成一个图像，并使该图像尽可能的接近真实图像以欺骗过判别器使判别器将生成器生成的图像当成真实图像。而判别器则尽可能的区分出生成器生成的图像和真实图像。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/ggan.jpg",alt:""}})]),t._v(" "),a("p",[t._v("生成对抗网络的结构及损失函数")]),t._v(" "),a("Mermaid",{attrs:{id:"mermaid_382ee204",code:t.$dataBlock.mermaid_382ee204}}),a("p",[t._v("代码实现可参考"),a("a",{attrs:{href:"https://gitee.com/lx_r/object_detection_task/tree/main/cv_examples/tf_tutorials/gan_tutorials",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("gitee仓库")]),a("OutboundLink")],1)]),t._v(" "),a("InArticleAdsense",{attrs:{"data-ad-client":"ca-pub-8685746128991385","data-ad-slot":"2974191661"}}),t._v(" "),a("h3",{attrs:{id:"参考资料"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),a("blockquote",[a("ul",[a("li",[a("a",{attrs:{href:"http://introtodeeplearning.com/",target:"_blank",rel:"noopener noreferrer"}},[t._v("1.DeepLearning"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/25401928",target:"_blank",rel:"noopener noreferrer"}},[t._v("2.VAE"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://spaces.ac.cn/archives/5253/comment-page-1#comments",target:"_blank",rel:"noopener noreferrer"}},[t._v("3.变分自编码器（一）：原来是这么一回事"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://www.tensorflow.org/tutorials/generative/dcgan",target:"_blank",rel:"noopener noreferrer"}},[t._v("4.深度卷积生成对抗网络"),a("OutboundLink")],1)])])])],1)}),[],!1,null,null,null);"function"==typeof r&&r(n);a.default=n.exports}}]);