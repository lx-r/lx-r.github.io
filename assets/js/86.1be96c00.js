(window.webpackJsonp=window.webpackJsonp||[]).push([[86],{401:function(t,a,s){"use strict";s.r(a);var n=s(17),r=Object(n.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"ocr文本识别crnn"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ocr文本识别crnn"}},[t._v("#")]),t._v(" OCR文本识别CRNN")]),t._v(" "),a("h2",{attrs:{id:"_1-基础介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-基础介绍"}},[t._v("#")]),t._v(" 1.基础介绍")]),t._v(" "),a("blockquote",[a("p",[t._v("论文:"),a("a",{attrs:{href:"https://arxiv.org/abs/1507.05717",target:"_blank",rel:"noopener noreferrer"}},[t._v("An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition"),a("OutboundLink")],1),t._v(" "),a("br"),a("br"),t._v("\nCode: "),a("a",{attrs:{href:"https://github.com/bgshih/crnn",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/bgshih/crnn"),a("OutboundLink")],1)])]),t._v(" "),a("p",[t._v("这篇论文是"),a("code",[t._v("2015")]),t._v("年"),a("code",[t._v("07")]),t._v("月份华中科技大学的"),a("code",[t._v("Baoguang Shi/Xiang Bai")]),t._v("等提交的。")]),t._v(" "),a("p",[t._v("文本识别是"),a("code",[t._v("OCR")]),t._v("任务中关键的一步，经过文本检测后可以获取文本区域的图像，文本识别可以将文本的图像"),a("code",[t._v("patch")]),t._v("转成字符序列。")]),t._v(" "),a("p",[t._v("这篇文章中提出的模型架构，将图像的特征提取/序列学习模型/文本转录做了整和，实现了模型的端到端训练。通过模型的整和，模型能够处理任意长度的序列，且对于有字典和无字典(lexicon)的任务都取得了比较好的效果。")]),t._v(" "),a("p",[t._v("论文中提出的四种方法的优势：")]),t._v(" "),a("ul",[a("li",[t._v("可端到端训练")]),t._v(" "),a("li",[t._v("可处理任意长度的文本序列")]),t._v(" "),a("li",[t._v("不需要限定字典")]),t._v(" "),a("li",[t._v("生成的模型更小")])]),t._v(" "),a("p",[t._v("提出模型的组成主要包括：")]),t._v(" "),a("div",{staticClass:"language-mermaid extra-class"},[a("pre",{pre:!0,attrs:{class:"language-mermaid"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("flowchart")]),t._v(" LR\nA"),a("span",{pre:!0,attrs:{class:"token text string"}},[t._v("(Input)")]),a("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v("B"),a("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[CNN]")]),t._v("\nB"),a("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[BiLSTM]")]),a("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v("D"),a("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[CTC]")]),t._v("\n")])])]),a("h2",{attrs:{id:"_2-crnn模型结构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-crnn模型结构"}},[t._v("#")]),t._v(" 2.CRNN模型结构")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn2w.jpg",alt:""}})]),t._v(" "),a("p",[t._v("从上图中可以看到模型主要包括三部分，卷积层提取特征，双向循环神经网络学习标签序列中的上下文信息，转录层将输出的冗余字符串通过"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:"MJX-TEX"},[a("mjx-TeXAtom",[a("mjx-mi",{staticClass:"mjx-cal"},[a("mjx-c",{attrs:{c:"B"}})],1)],1)],1)],1),t._v("。")],1),t._v(" "),a("h3",{attrs:{id:"_2-1-特征提取"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-特征提取"}},[t._v("#")]),t._v(" 2.1 特征提取")]),t._v(" "),a("p",[t._v("特征提取使用的是标准的卷积层+最大值池化的方法。图像在输入到"),a("code",[t._v("CNN")]),t._v("之前需要先将其高度"),a("code",[t._v("resize")]),t._v("到一个固定的数值，然后"),a("code",[t._v("CNN")]),t._v("的输出是高度为1的不定长特征序列向量，从左到右是相同维度的序列，作为"),a("code",[t._v("BiLSTM")]),t._v("的输入。特征序列向量的每一列对应原图像中的一个矩形区域：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn2p.jpg",alt:""}})]),t._v(" "),a("p",[t._v("例如输入为"),a("code",[t._v("(32,100,3)")]),t._v("的图像，经过"),a("code",[t._v("CNN")]),t._v("特征提取后输出的序列特征的"),a("code",[t._v("shape")]),t._v("为"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:"MJX-TEX"},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"2"}}),a("mjx-c",{attrs:{c:"5"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:","}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"2"}},[a("mjx-c",{attrs:{c:"5"}}),a("mjx-c",{attrs:{c:"1"}}),a("mjx-c",{attrs:{c:"2"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t._v(" "),a("h3",{attrs:{id:"_2-2-双向循环神经网络层"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-双向循环神经网络层"}},[t._v("#")]),t._v(" 2.2 双向循环神经网络层")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn3.jpg",alt:""}})]),t._v(" "),a("p",[t._v("循环神经网络(Recurrent Neural Network,RNN)从其定义，中间使用了隐含层的信息传递，使得其具有了序列预测的能力。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn4.jpg",alt:""}})]),t._v(" "),a("p",[t._v("但是当序列的长度比较长的时候，一个位置的预测依赖更远的先前语义信息时，"),a("code",[t._v("RNN")]),t._v("的表现就有些弱了，例如，使用"),a("code",[t._v("RNN")]),t._v("的语言模型在处理"),a("code",[t._v("I grew up in France… I speak fluent French.")]),t._v("，从"),a("code",[t._v("French")]),t._v("比较近的上下文可以知道"),a("code",[t._v("speak fluent")]),t._v("后面应该时语言，但借助更久远的信息"),a("code",[t._v("in France")]),t._v("能进一步推断应该是"),a("code",[t._v("French")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn5.jpg",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"http://colah.github.io/posts/2015-08-Understanding-LSTMs/",target:"_blank",rel:"noopener noreferrer"}},[t._v("长短期记忆网络"),a("OutboundLink")],1),t._v("(Long Short Term Memory,LSTM)的提出正是"),a("br"),t._v("\n对"),a("code",[t._v("RNN")]),t._v("的改进，为了解决RNN不能处理的长期依赖问题，"),a("code",[t._v("LSTM")]),t._v("中上部的"),a("code",[t._v("C_t")]),t._v("那条线使得信息能够从较远的过去传递到当前的位置，"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:"MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3C3"}})],1)],1)],1),t._v("函数的使用又让"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:"MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"S"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"M"}})],1)],1)],1),t._v("能够选择性的记忆或遗忘传递过来的信息，因此"),a("code",[t._v("LSTM")]),t._v("能更好的处理远期依赖的问题。")],1),t._v(" "),a("p",[t._v("从前面图中可以看到"),a("code",[t._v("LSTM")]),t._v("和传统的"),a("code",[t._v("RNN")]),t._v("模型只能从左侧向右侧传递依赖信息，但实际上在处理序列数据时可以同时利用序列当前位置左侧和右侧的信息来共同处理，"),a("code",[t._v("Bilateral Direction LSTM")]),t._v("使用两条路径，"),a("a",{attrs:{href:"https://www.baeldung.com/cs/bidirectional-vs-unidirectional-lstm",target:"_blank",rel:"noopener noreferrer"}},[t._v("实现了利用左右侧上下文信息来做推理"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn6.jpg",alt:""}})]),t._v(" "),a("p",[a("code",[t._v("Pytorch.nn")]),t._v("模块中实现的"),a("code",[t._v("LSTM")]),t._v("层，通过参数可以直接控制"),a("code",[t._v("LSTM")]),t._v("的层数和是否是双向"),a("code",[t._v("LSTM")]),t._v("。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RNNBase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hidden_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 num_layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bias"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 dropout"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bidirectional"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("LSTM")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RNNBase"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n     "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),a("h3",{attrs:{id:"_2-3-转录层-transcription-layers"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-转录层-transcription-layers"}},[t._v("#")]),t._v(" 2.3 转录层(Transcription Layers)")]),t._v(" "),a("p",[a("code",[t._v("BiLSTM")]),t._v("的输出"),a("code",[t._v("Shape")]),t._v("为(N,T,C)，"),a("code",[t._v("N")]),t._v("是"),a("code",[t._v("Batch Size")]),t._v(","),a("code",[t._v("T")]),t._v("是序列长度,"),a("code",[t._v("C")]),t._v("是序列每个位置可能的取值类别数(字典中字符的个数)，对输出在维度"),a("code",[t._v("2")]),t._v("上做"),a("code",[t._v("softmax")]),t._v("得到的就是序列每个位置字符取值的概率。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/crnn7.jpg",alt:""}})]),t._v(" "),a("p",[t._v("在模型训练时，因为"),a("code",[t._v("CNN")]),t._v("提取的特征长度是不固定的，和图像对应的字符串之间也没有对应关系，因此直接从这种未切分的数据中直接学习字符串序列需要使用特殊的方法，文章作者使用的是2006年一篇文章中提出的"),a("code",[t._v("Connectionist Temporal Classification(CTC)")]),t._v("算法，这一部分是"),a("code",[t._v("CRNN")]),t._v("模型能之间从字符串图像中直接学习的关键，"),a("a",{attrs:{href:"https://foobarweb.net/2023/02/20/3CTC/#more",target:"_blank",rel:"noopener noreferrer"}},[t._v("具体可以参考另一篇文章的详细介绍"),a("OutboundLink")],1)]),t._v(" "),a("InArticleAdsense",{attrs:{"data-ad-client":"ca-pub-8685746128991385","data-ad-slot":"2974191661"}}),t._v(" "),a("h3",{attrs:{id:"参考资料"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),a("blockquote",[a("ul",[a("li",[a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/43534801",target:"_blank",rel:"noopener noreferrer"}},[t._v("1.https://zhuanlan.zhihu.com/p/43534801"),a("OutboundLink")],1)])])])],1)}),[],!1,null,null,null);a.default=r.exports}}]);