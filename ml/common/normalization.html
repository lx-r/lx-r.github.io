<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>数据归一化方法BN/LN/GN/IN | GoldNotes</title>
    <meta name="generator" content="VuePress 1.9.10">
    <script>
            var _hmt = _hmt || [];
            (function() {
            // 引入谷歌,不需要可删除这段
            var hm1 = document.createElement("script");
            hm1.src = "https://www.googletagmanager.com/gtag/js?id=G-BDK0Y9WWLP";
            var s1 = document.getElementsByTagName("script")[0]; 
            s1.parentNode.insertBefore(hm1, s1);
            })();
            // 谷歌加载,不需要可删除
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-BDK0Y9WWLP');
        </script>
    <link rel="icon" href="/logo.png">
    <script data-ad-client="ca-pub-8685746128991385" async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="Just playing around">
    
    <link rel="preload" href="/assets/css/0.styles.c5e7512f.css" as="style"><link rel="preload" href="/assets/js/app.4fb1e7ac.js" as="script"><link rel="preload" href="/assets/js/2.441eb26f.js" as="script"><link rel="preload" href="/assets/js/1.1a1c696e.js" as="script"><link rel="preload" href="/assets/js/221.d10aa87c.js" as="script"><link rel="prefetch" href="/assets/js/10.5a2e9b6f.js"><link rel="prefetch" href="/assets/js/100.ef80225f.js"><link rel="prefetch" href="/assets/js/101.e15d219a.js"><link rel="prefetch" href="/assets/js/102.d6f75c18.js"><link rel="prefetch" href="/assets/js/103.12816430.js"><link rel="prefetch" href="/assets/js/104.7cafc7da.js"><link rel="prefetch" href="/assets/js/105.a95fe706.js"><link rel="prefetch" href="/assets/js/106.f9124e10.js"><link rel="prefetch" href="/assets/js/107.8ff67460.js"><link rel="prefetch" href="/assets/js/108.f9d986f5.js"><link rel="prefetch" href="/assets/js/109.32bd2df3.js"><link rel="prefetch" href="/assets/js/11.3e0edbf0.js"><link rel="prefetch" href="/assets/js/110.313ef3df.js"><link rel="prefetch" href="/assets/js/111.b8637dcf.js"><link rel="prefetch" href="/assets/js/112.9e6011d2.js"><link rel="prefetch" href="/assets/js/113.63c9a458.js"><link rel="prefetch" href="/assets/js/114.50d79414.js"><link rel="prefetch" href="/assets/js/115.f6673090.js"><link rel="prefetch" href="/assets/js/116.a6d8417d.js"><link rel="prefetch" href="/assets/js/117.7e612414.js"><link rel="prefetch" href="/assets/js/118.d92d9409.js"><link rel="prefetch" href="/assets/js/119.ebe75303.js"><link rel="prefetch" href="/assets/js/12.9a49b12f.js"><link rel="prefetch" href="/assets/js/120.552b6b09.js"><link rel="prefetch" href="/assets/js/121.db70210c.js"><link rel="prefetch" href="/assets/js/122.6f43bbfe.js"><link rel="prefetch" href="/assets/js/123.fad382fe.js"><link rel="prefetch" href="/assets/js/124.fc7d5e6b.js"><link rel="prefetch" href="/assets/js/125.644c16a8.js"><link rel="prefetch" href="/assets/js/126.b554f501.js"><link rel="prefetch" href="/assets/js/127.5d9889cb.js"><link rel="prefetch" href="/assets/js/128.7465973e.js"><link rel="prefetch" href="/assets/js/129.f3d49d26.js"><link rel="prefetch" href="/assets/js/13.c98d76f0.js"><link rel="prefetch" href="/assets/js/130.7f786c09.js"><link rel="prefetch" href="/assets/js/131.c588a4e5.js"><link rel="prefetch" href="/assets/js/132.a9d8f9d7.js"><link rel="prefetch" href="/assets/js/133.40e52588.js"><link rel="prefetch" href="/assets/js/134.46e589a3.js"><link rel="prefetch" href="/assets/js/135.22363a46.js"><link rel="prefetch" href="/assets/js/136.6ed1697a.js"><link rel="prefetch" href="/assets/js/137.85561c69.js"><link rel="prefetch" href="/assets/js/138.99a04494.js"><link rel="prefetch" href="/assets/js/139.f0552c7a.js"><link rel="prefetch" href="/assets/js/14.c033f4de.js"><link rel="prefetch" href="/assets/js/140.4ec1e061.js"><link rel="prefetch" href="/assets/js/141.a9837bb8.js"><link rel="prefetch" href="/assets/js/142.0daf24d0.js"><link rel="prefetch" href="/assets/js/143.f9fc0d3f.js"><link rel="prefetch" href="/assets/js/144.755f8542.js"><link rel="prefetch" href="/assets/js/145.fd3d789b.js"><link rel="prefetch" href="/assets/js/146.c2c62b01.js"><link rel="prefetch" href="/assets/js/147.f946170d.js"><link rel="prefetch" href="/assets/js/148.7733f24d.js"><link rel="prefetch" href="/assets/js/149.5d54ce19.js"><link rel="prefetch" href="/assets/js/15.6900fe6f.js"><link rel="prefetch" href="/assets/js/150.09134583.js"><link rel="prefetch" href="/assets/js/151.7522945c.js"><link rel="prefetch" href="/assets/js/152.808bd1b6.js"><link rel="prefetch" href="/assets/js/153.0af3f06c.js"><link rel="prefetch" href="/assets/js/154.53831122.js"><link rel="prefetch" href="/assets/js/155.53e5bdc3.js"><link rel="prefetch" href="/assets/js/156.8923d841.js"><link rel="prefetch" href="/assets/js/157.04fb08da.js"><link rel="prefetch" href="/assets/js/158.0e6663e8.js"><link rel="prefetch" href="/assets/js/159.2670449b.js"><link rel="prefetch" href="/assets/js/16.5077eb29.js"><link rel="prefetch" href="/assets/js/160.3fc6588a.js"><link rel="prefetch" href="/assets/js/161.7875402e.js"><link rel="prefetch" href="/assets/js/162.541ec610.js"><link rel="prefetch" href="/assets/js/163.c17ccbc0.js"><link rel="prefetch" href="/assets/js/164.86fce3b4.js"><link rel="prefetch" href="/assets/js/165.2b9548d0.js"><link rel="prefetch" href="/assets/js/166.66a2805f.js"><link rel="prefetch" href="/assets/js/167.4de98e57.js"><link rel="prefetch" href="/assets/js/168.6f000eaa.js"><link rel="prefetch" href="/assets/js/169.cda36066.js"><link rel="prefetch" href="/assets/js/17.112268e5.js"><link rel="prefetch" href="/assets/js/170.3f1ae11a.js"><link rel="prefetch" href="/assets/js/171.ae67c120.js"><link rel="prefetch" href="/assets/js/172.6f2bed6e.js"><link rel="prefetch" href="/assets/js/173.2b8efaa1.js"><link rel="prefetch" href="/assets/js/174.01667775.js"><link rel="prefetch" href="/assets/js/175.b6b57c90.js"><link rel="prefetch" href="/assets/js/176.241f6966.js"><link rel="prefetch" href="/assets/js/177.20a02334.js"><link rel="prefetch" href="/assets/js/178.a338760c.js"><link rel="prefetch" href="/assets/js/179.d31d1033.js"><link rel="prefetch" href="/assets/js/18.b015dc58.js"><link rel="prefetch" href="/assets/js/180.5292fa26.js"><link rel="prefetch" href="/assets/js/181.d76d57b6.js"><link rel="prefetch" href="/assets/js/182.e53b7eee.js"><link rel="prefetch" href="/assets/js/183.dd36cb6c.js"><link rel="prefetch" href="/assets/js/184.8c5d1acd.js"><link rel="prefetch" href="/assets/js/185.0fa69241.js"><link rel="prefetch" href="/assets/js/186.a060dcfc.js"><link rel="prefetch" href="/assets/js/187.7c5dd016.js"><link rel="prefetch" href="/assets/js/188.e1d6eb59.js"><link rel="prefetch" href="/assets/js/189.d080da82.js"><link rel="prefetch" href="/assets/js/19.a730210d.js"><link rel="prefetch" href="/assets/js/190.5ea05bc2.js"><link rel="prefetch" href="/assets/js/191.ccce8c21.js"><link rel="prefetch" href="/assets/js/192.8919b9f4.js"><link rel="prefetch" href="/assets/js/193.53a2231c.js"><link rel="prefetch" href="/assets/js/194.7dc4768d.js"><link rel="prefetch" href="/assets/js/195.1f14c2d3.js"><link rel="prefetch" href="/assets/js/196.95e1de51.js"><link rel="prefetch" href="/assets/js/197.61f1490e.js"><link rel="prefetch" href="/assets/js/198.c16e311f.js"><link rel="prefetch" href="/assets/js/199.a0463af3.js"><link rel="prefetch" href="/assets/js/20.a01ca174.js"><link rel="prefetch" href="/assets/js/200.88a1d097.js"><link rel="prefetch" href="/assets/js/201.ccd16283.js"><link rel="prefetch" href="/assets/js/202.63c30104.js"><link rel="prefetch" href="/assets/js/203.75cacf3b.js"><link rel="prefetch" href="/assets/js/204.78d81202.js"><link rel="prefetch" href="/assets/js/205.428844a4.js"><link rel="prefetch" href="/assets/js/206.536ab8ea.js"><link rel="prefetch" href="/assets/js/207.1d6ea039.js"><link rel="prefetch" href="/assets/js/208.559fa16a.js"><link rel="prefetch" href="/assets/js/209.024c14ee.js"><link rel="prefetch" href="/assets/js/21.56e4f12e.js"><link rel="prefetch" href="/assets/js/210.b4e24295.js"><link rel="prefetch" href="/assets/js/211.59133109.js"><link rel="prefetch" href="/assets/js/212.2c11bc51.js"><link rel="prefetch" href="/assets/js/213.4124dac6.js"><link rel="prefetch" href="/assets/js/214.3fe2516e.js"><link rel="prefetch" href="/assets/js/215.aef02404.js"><link rel="prefetch" href="/assets/js/216.02f537aa.js"><link rel="prefetch" href="/assets/js/217.4fb1b7ef.js"><link rel="prefetch" href="/assets/js/218.2effa1a4.js"><link rel="prefetch" href="/assets/js/219.c1de57a8.js"><link rel="prefetch" href="/assets/js/22.fcddc1c6.js"><link rel="prefetch" href="/assets/js/220.b5062ce2.js"><link rel="prefetch" href="/assets/js/222.174a73b7.js"><link rel="prefetch" href="/assets/js/223.6bd66640.js"><link rel="prefetch" href="/assets/js/224.60738e78.js"><link rel="prefetch" href="/assets/js/225.29e10b6a.js"><link rel="prefetch" href="/assets/js/226.41609457.js"><link rel="prefetch" href="/assets/js/227.5d2a1817.js"><link rel="prefetch" href="/assets/js/228.ae086e62.js"><link rel="prefetch" href="/assets/js/229.23dbfd01.js"><link rel="prefetch" href="/assets/js/23.c542ac54.js"><link rel="prefetch" href="/assets/js/230.846276a3.js"><link rel="prefetch" href="/assets/js/231.a85ab6e0.js"><link rel="prefetch" href="/assets/js/232.0b6e6b4c.js"><link rel="prefetch" href="/assets/js/233.6cb92776.js"><link rel="prefetch" href="/assets/js/234.cea1dee5.js"><link rel="prefetch" href="/assets/js/235.500e92ea.js"><link rel="prefetch" href="/assets/js/236.bbc42488.js"><link rel="prefetch" href="/assets/js/237.2a724798.js"><link rel="prefetch" href="/assets/js/238.4ab2349d.js"><link rel="prefetch" href="/assets/js/239.d0bfc9cf.js"><link rel="prefetch" href="/assets/js/24.b876b0b7.js"><link rel="prefetch" href="/assets/js/240.605bb0c5.js"><link rel="prefetch" href="/assets/js/241.9570c994.js"><link rel="prefetch" href="/assets/js/242.18d655b8.js"><link rel="prefetch" href="/assets/js/243.1001542c.js"><link rel="prefetch" href="/assets/js/244.b6b11929.js"><link rel="prefetch" href="/assets/js/245.80f35f7e.js"><link rel="prefetch" href="/assets/js/246.33b89f85.js"><link rel="prefetch" href="/assets/js/247.7b6887c5.js"><link rel="prefetch" href="/assets/js/248.63719a2c.js"><link rel="prefetch" href="/assets/js/249.67a27bcb.js"><link rel="prefetch" href="/assets/js/25.1dcefbee.js"><link rel="prefetch" href="/assets/js/250.b26d162c.js"><link rel="prefetch" href="/assets/js/251.c796b53a.js"><link rel="prefetch" href="/assets/js/252.1305b2c8.js"><link rel="prefetch" href="/assets/js/253.032816e3.js"><link rel="prefetch" href="/assets/js/254.a40ea038.js"><link rel="prefetch" href="/assets/js/255.f961cc57.js"><link rel="prefetch" href="/assets/js/256.db863c94.js"><link rel="prefetch" href="/assets/js/257.d4fbd9ba.js"><link rel="prefetch" href="/assets/js/258.e75fd178.js"><link rel="prefetch" href="/assets/js/259.86faea64.js"><link rel="prefetch" href="/assets/js/26.59e81884.js"><link rel="prefetch" href="/assets/js/260.5052982a.js"><link rel="prefetch" href="/assets/js/261.e5150bda.js"><link rel="prefetch" href="/assets/js/262.d38b609d.js"><link rel="prefetch" href="/assets/js/263.6e33b2d1.js"><link rel="prefetch" href="/assets/js/264.bbb4378b.js"><link rel="prefetch" href="/assets/js/265.c10f1cb4.js"><link rel="prefetch" href="/assets/js/266.da1848ad.js"><link rel="prefetch" href="/assets/js/267.669cad05.js"><link rel="prefetch" href="/assets/js/268.849e9b54.js"><link rel="prefetch" href="/assets/js/269.db147d70.js"><link rel="prefetch" href="/assets/js/27.c6d3d68b.js"><link rel="prefetch" href="/assets/js/270.d7a9657a.js"><link rel="prefetch" href="/assets/js/271.7780769c.js"><link rel="prefetch" href="/assets/js/272.87997591.js"><link rel="prefetch" href="/assets/js/273.f97c10b8.js"><link rel="prefetch" href="/assets/js/274.21a985e4.js"><link rel="prefetch" href="/assets/js/275.26455192.js"><link rel="prefetch" href="/assets/js/276.a7c80ed1.js"><link rel="prefetch" href="/assets/js/277.c3387517.js"><link rel="prefetch" href="/assets/js/278.b8efb02b.js"><link rel="prefetch" href="/assets/js/279.28947d1f.js"><link rel="prefetch" href="/assets/js/28.6f255334.js"><link rel="prefetch" href="/assets/js/280.9d7368cd.js"><link rel="prefetch" href="/assets/js/281.536ed57f.js"><link rel="prefetch" href="/assets/js/282.bc9c2104.js"><link rel="prefetch" href="/assets/js/283.be87340c.js"><link rel="prefetch" href="/assets/js/284.85f91dd9.js"><link rel="prefetch" href="/assets/js/285.c997d364.js"><link rel="prefetch" href="/assets/js/29.ff17d212.js"><link rel="prefetch" href="/assets/js/3.939eb1e6.js"><link rel="prefetch" href="/assets/js/30.de8e75fd.js"><link rel="prefetch" href="/assets/js/31.2237e84f.js"><link rel="prefetch" href="/assets/js/32.24ea6ffd.js"><link rel="prefetch" href="/assets/js/33.24c84eee.js"><link rel="prefetch" href="/assets/js/34.7d7c5d30.js"><link rel="prefetch" href="/assets/js/35.e122dd64.js"><link rel="prefetch" href="/assets/js/36.62df0b93.js"><link rel="prefetch" href="/assets/js/37.df57cb81.js"><link rel="prefetch" href="/assets/js/38.3ec5fc5b.js"><link rel="prefetch" href="/assets/js/39.390a3693.js"><link rel="prefetch" href="/assets/js/4.61dbd51c.js"><link rel="prefetch" href="/assets/js/40.55d80750.js"><link rel="prefetch" href="/assets/js/41.2ab0a6ab.js"><link rel="prefetch" href="/assets/js/42.64bcd0f8.js"><link rel="prefetch" href="/assets/js/43.8b758d29.js"><link rel="prefetch" href="/assets/js/44.01f440d3.js"><link rel="prefetch" href="/assets/js/45.215f31f9.js"><link rel="prefetch" href="/assets/js/46.2841afe2.js"><link rel="prefetch" href="/assets/js/47.f898542e.js"><link rel="prefetch" href="/assets/js/48.d71a0437.js"><link rel="prefetch" href="/assets/js/49.09e4d0dc.js"><link rel="prefetch" href="/assets/js/5.8404b813.js"><link rel="prefetch" href="/assets/js/50.ca870680.js"><link rel="prefetch" href="/assets/js/51.76cb8363.js"><link rel="prefetch" href="/assets/js/52.7746a702.js"><link rel="prefetch" href="/assets/js/53.92e1e16d.js"><link rel="prefetch" href="/assets/js/54.565d805f.js"><link rel="prefetch" href="/assets/js/55.cd788d8f.js"><link rel="prefetch" href="/assets/js/56.8f7bf723.js"><link rel="prefetch" href="/assets/js/57.91a0d761.js"><link rel="prefetch" href="/assets/js/58.f642e24a.js"><link rel="prefetch" href="/assets/js/59.2a8e3be6.js"><link rel="prefetch" href="/assets/js/6.9c81633d.js"><link rel="prefetch" href="/assets/js/60.c832cb65.js"><link rel="prefetch" href="/assets/js/61.fe244e14.js"><link rel="prefetch" href="/assets/js/62.a6df731e.js"><link rel="prefetch" href="/assets/js/63.2d9337d6.js"><link rel="prefetch" href="/assets/js/64.175c6cf8.js"><link rel="prefetch" href="/assets/js/65.71d399f4.js"><link rel="prefetch" href="/assets/js/66.c2ff4239.js"><link rel="prefetch" href="/assets/js/67.2520b141.js"><link rel="prefetch" href="/assets/js/68.5e59ea8f.js"><link rel="prefetch" href="/assets/js/69.ef86b576.js"><link rel="prefetch" href="/assets/js/7.0dcde973.js"><link rel="prefetch" href="/assets/js/70.b6a38514.js"><link rel="prefetch" href="/assets/js/71.6891db67.js"><link rel="prefetch" href="/assets/js/72.875d6b6d.js"><link rel="prefetch" href="/assets/js/73.7b2a501e.js"><link rel="prefetch" href="/assets/js/74.58bab29f.js"><link rel="prefetch" href="/assets/js/75.07cbc52d.js"><link rel="prefetch" href="/assets/js/76.4abced12.js"><link rel="prefetch" href="/assets/js/77.7d6f96ed.js"><link rel="prefetch" href="/assets/js/78.bcf6d0aa.js"><link rel="prefetch" href="/assets/js/79.518f153c.js"><link rel="prefetch" href="/assets/js/80.28a5affe.js"><link rel="prefetch" href="/assets/js/81.b454a9d9.js"><link rel="prefetch" href="/assets/js/82.d1cece4c.js"><link rel="prefetch" href="/assets/js/83.206656f4.js"><link rel="prefetch" href="/assets/js/84.f148ca2a.js"><link rel="prefetch" href="/assets/js/85.49862eae.js"><link rel="prefetch" href="/assets/js/86.1be96c00.js"><link rel="prefetch" href="/assets/js/87.29271ed2.js"><link rel="prefetch" href="/assets/js/88.f0267ae8.js"><link rel="prefetch" href="/assets/js/89.74e42f1e.js"><link rel="prefetch" href="/assets/js/90.c2d94a52.js"><link rel="prefetch" href="/assets/js/91.8567aa93.js"><link rel="prefetch" href="/assets/js/92.44b8dd08.js"><link rel="prefetch" href="/assets/js/93.4d546387.js"><link rel="prefetch" href="/assets/js/94.6d4c5937.js"><link rel="prefetch" href="/assets/js/95.67ba4aea.js"><link rel="prefetch" href="/assets/js/96.5137f1ee.js"><link rel="prefetch" href="/assets/js/97.5861f7e7.js"><link rel="prefetch" href="/assets/js/98.80a7594c.js"><link rel="prefetch" href="/assets/js/99.4236959e.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.6fed1ae2.js">
    <link rel="stylesheet" href="/assets/css/0.styles.c5e7512f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">GoldNotes</span></a> <div class="links"><nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="计算机视觉" class="dropdown-title"><span class="title">计算机视觉</span> <span class="arrow down"></span></button> <button type="button" aria-label="计算机视觉" class="mobile-dropdown-title"><span class="title">计算机视觉</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/cv/dip/" class="nav-link">
  学习图像处理
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection/" class="nav-link">
  学习目标检测
</a></li><li class="dropdown-item"><!----> <a href="/cv/segmentation/" class="nav-link">
  学习语义分割
</a></li><li class="dropdown-item"><!----> <a href="/cv/ocr/" class="nav-link">
  学习OCR
</a></li><li class="dropdown-item"><!----> <a href="/cv/human-pose/" class="nav-link">
  学习姿态估计
</a></li><li class="dropdown-item"><!----> <a href="/cv/gan/" class="nav-link">
  学习生成对抗网络
</a></li><li class="dropdown-item"><!----> <a href="/cv/datasets/" class="nav-link">
  学习开源数据
</a></li><li class="dropdown-item"><!----> <a href="/cv/tracking/" class="nav-link">
  学习目标追踪
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection3d/" class="nav-link">
  学习3D目标检测
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法框架" class="dropdown-title"><span class="title">算法框架</span> <span class="arrow down"></span></button> <button type="button" aria-label="算法框架" class="mobile-dropdown-title"><span class="title">算法框架</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ai/opencv/" class="nav-link">
  学习OpenCV
</a></li><li class="dropdown-item"><!----> <a href="/ai/torch/" class="nav-link">
  学习pytorch
</a></li><li class="dropdown-item"><!----> <a href="/ai/cuda/" class="nav-link">
  学习CUDA
</a></li><li class="dropdown-item"><!----> <a href="/ai/tensorflow/" class="nav-link">
  学习tensorflow
</a></li><li class="dropdown-item"><!----> <a href="/ai/onnx/" class="nav-link">
  学习ONNX
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="机器学习" class="dropdown-title"><span class="title">机器学习</span> <span class="arrow down"></span></button> <button type="button" aria-label="机器学习" class="mobile-dropdown-title"><span class="title">机器学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ml/gnn/" class="nav-link">
  学习图算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/singleclass/" class="nav-link">
  学习单分类算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/oneshot/" class="nav-link">
  学习小样本算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/common/" class="nav-link router-link-active">
  学习常用算法
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="操作系统" class="dropdown-title"><span class="title">操作系统</span> <span class="arrow down"></span></button> <button type="button" aria-label="操作系统" class="mobile-dropdown-title"><span class="title">操作系统</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/system/" class="nav-link">
  学习操作系统
</a></li><li class="dropdown-item"><!----> <a href="/system/linux/" class="nav-link">
  学习linux
</a></li><li class="dropdown-item"><!----> <a href="/system/ros/" class="nav-link">
  学习ROS
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/langs/se/" class="nav-link">
  学习软件开发
</a></li><li class="dropdown-item"><!----> <a href="/langs/python/" class="nav-link">
  学习Python
</a></li><li class="dropdown-item"><!----> <a href="/langs/cpp/" class="nav-link">
  学习C++
</a></li><li class="dropdown-item"><!----> <a href="/langs/yaml/" class="nav-link">
  学习yaml
</a></li><li class="dropdown-item"><!----> <a href="/langs/sqlite/" class="nav-link">
  学习sql
</a></li><li class="dropdown-item"><!----> <a href="/langs/shell/" class="nav-link">
  学习shell
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="IT工具" class="dropdown-title"><span class="title">IT工具</span> <span class="arrow down"></span></button> <button type="button" aria-label="IT工具" class="mobile-dropdown-title"><span class="title">IT工具</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tools/git/" class="nav-link">
  学习GIT
</a></li><li class="dropdown-item"><!----> <a href="/tools/docker/" class="nav-link">
  学习Docker
</a></li><li class="dropdown-item"><!----> <a href="/tools/gimp/" class="nav-link">
  学习GIMP
</a></li><li class="dropdown-item"><!----> <a href="/tools/vscode/" class="nav-link">
  学习VSCode
</a></li><li class="dropdown-item"><!----> <a href="/tools/hexo/" class="nav-link">
  学习hexo
</a></li><li class="dropdown-item"><!----> <a href="/tools/others/" class="nav-link">
  学习常用工具
</a></li><li class="dropdown-item"><!----> <a href="/tools/leetcodes/" class="nav-link">
  基础算法刷题
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数学知识" class="dropdown-title"><span class="title">数学知识</span> <span class="arrow down"></span></button> <button type="button" aria-label="数学知识" class="mobile-dropdown-title"><span class="title">数学知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/math/statistics/" class="nav-link">
  学习概率统计
</a></li><li class="dropdown-item"><!----> <a href="/math/linear-algebra/" class="nav-link">
  学习线性代数
</a></li><li class="dropdown-item"><!----> <a href="/math/calculus/" class="nav-link">
  学习高等数学
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="理财基础" class="dropdown-title"><span class="title">理财基础</span> <span class="arrow down"></span></button> <button type="button" aria-label="理财基础" class="mobile-dropdown-title"><span class="title">理财基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/finance/evaluate.html" class="nav-link">
  评测指标
</a></li></ul></div></div> <!----></nav> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="计算机视觉" class="dropdown-title"><span class="title">计算机视觉</span> <span class="arrow down"></span></button> <button type="button" aria-label="计算机视觉" class="mobile-dropdown-title"><span class="title">计算机视觉</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/cv/dip/" class="nav-link">
  学习图像处理
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection/" class="nav-link">
  学习目标检测
</a></li><li class="dropdown-item"><!----> <a href="/cv/segmentation/" class="nav-link">
  学习语义分割
</a></li><li class="dropdown-item"><!----> <a href="/cv/ocr/" class="nav-link">
  学习OCR
</a></li><li class="dropdown-item"><!----> <a href="/cv/human-pose/" class="nav-link">
  学习姿态估计
</a></li><li class="dropdown-item"><!----> <a href="/cv/gan/" class="nav-link">
  学习生成对抗网络
</a></li><li class="dropdown-item"><!----> <a href="/cv/datasets/" class="nav-link">
  学习开源数据
</a></li><li class="dropdown-item"><!----> <a href="/cv/tracking/" class="nav-link">
  学习目标追踪
</a></li><li class="dropdown-item"><!----> <a href="/cv/detection3d/" class="nav-link">
  学习3D目标检测
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法框架" class="dropdown-title"><span class="title">算法框架</span> <span class="arrow down"></span></button> <button type="button" aria-label="算法框架" class="mobile-dropdown-title"><span class="title">算法框架</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ai/opencv/" class="nav-link">
  学习OpenCV
</a></li><li class="dropdown-item"><!----> <a href="/ai/torch/" class="nav-link">
  学习pytorch
</a></li><li class="dropdown-item"><!----> <a href="/ai/cuda/" class="nav-link">
  学习CUDA
</a></li><li class="dropdown-item"><!----> <a href="/ai/tensorflow/" class="nav-link">
  学习tensorflow
</a></li><li class="dropdown-item"><!----> <a href="/ai/onnx/" class="nav-link">
  学习ONNX
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="机器学习" class="dropdown-title"><span class="title">机器学习</span> <span class="arrow down"></span></button> <button type="button" aria-label="机器学习" class="mobile-dropdown-title"><span class="title">机器学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/ml/gnn/" class="nav-link">
  学习图算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/singleclass/" class="nav-link">
  学习单分类算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/oneshot/" class="nav-link">
  学习小样本算法
</a></li><li class="dropdown-item"><!----> <a href="/ml/common/" class="nav-link router-link-active">
  学习常用算法
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="操作系统" class="dropdown-title"><span class="title">操作系统</span> <span class="arrow down"></span></button> <button type="button" aria-label="操作系统" class="mobile-dropdown-title"><span class="title">操作系统</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/system/" class="nav-link">
  学习操作系统
</a></li><li class="dropdown-item"><!----> <a href="/system/linux/" class="nav-link">
  学习linux
</a></li><li class="dropdown-item"><!----> <a href="/system/ros/" class="nav-link">
  学习ROS
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/langs/se/" class="nav-link">
  学习软件开发
</a></li><li class="dropdown-item"><!----> <a href="/langs/python/" class="nav-link">
  学习Python
</a></li><li class="dropdown-item"><!----> <a href="/langs/cpp/" class="nav-link">
  学习C++
</a></li><li class="dropdown-item"><!----> <a href="/langs/yaml/" class="nav-link">
  学习yaml
</a></li><li class="dropdown-item"><!----> <a href="/langs/sqlite/" class="nav-link">
  学习sql
</a></li><li class="dropdown-item"><!----> <a href="/langs/shell/" class="nav-link">
  学习shell
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="IT工具" class="dropdown-title"><span class="title">IT工具</span> <span class="arrow down"></span></button> <button type="button" aria-label="IT工具" class="mobile-dropdown-title"><span class="title">IT工具</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tools/git/" class="nav-link">
  学习GIT
</a></li><li class="dropdown-item"><!----> <a href="/tools/docker/" class="nav-link">
  学习Docker
</a></li><li class="dropdown-item"><!----> <a href="/tools/gimp/" class="nav-link">
  学习GIMP
</a></li><li class="dropdown-item"><!----> <a href="/tools/vscode/" class="nav-link">
  学习VSCode
</a></li><li class="dropdown-item"><!----> <a href="/tools/hexo/" class="nav-link">
  学习hexo
</a></li><li class="dropdown-item"><!----> <a href="/tools/others/" class="nav-link">
  学习常用工具
</a></li><li class="dropdown-item"><!----> <a href="/tools/leetcodes/" class="nav-link">
  基础算法刷题
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数学知识" class="dropdown-title"><span class="title">数学知识</span> <span class="arrow down"></span></button> <button type="button" aria-label="数学知识" class="mobile-dropdown-title"><span class="title">数学知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/math/statistics/" class="nav-link">
  学习概率统计
</a></li><li class="dropdown-item"><!----> <a href="/math/linear-algebra/" class="nav-link">
  学习线性代数
</a></li><li class="dropdown-item"><!----> <a href="/math/calculus/" class="nav-link">
  学习高等数学
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="理财基础" class="dropdown-title"><span class="title">理财基础</span> <span class="arrow down"></span></button> <button type="button" aria-label="理财基础" class="mobile-dropdown-title"><span class="title">理财基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/finance/evaluate.html" class="nav-link">
  评测指标
</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>学习常用ML算法</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ml/common/" aria-current="page" class="sidebar-link">Global Contrast Normalization</a></li><li><a href="/ml/common/sklearn-cls-metric.html" class="sidebar-link">sklearn.metrics.classification_report中的Micro/Macro/Weighted Average指标</a></li><li><a href="/ml/common/transconv.html" class="sidebar-link">转置卷积</a></li><li><a href="/ml/common/ce.html" class="sidebar-link">带权重和ignore_index的交叉商损失函数</a></li><li><a href="/ml/common/bilinear.html" class="sidebar-link">双线性插值算法</a></li><li><a href="/ml/common/depthwise-cnn.html" class="sidebar-link">深度可分离卷积</a></li><li><a href="/ml/common/nnoptimization.html" class="sidebar-link">神经网络参数优化</a></li><li><a href="/ml/common/normalization.html" aria-current="page" class="active sidebar-link">数据归一化方法BN/LN/GN/IN</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/ml/common/normalization.html#_0-introduction" class="sidebar-link">0. Introduction</a></li><li class="sidebar-sub-header"><a href="/ml/common/normalization.html#_1-batch-normalization" class="sidebar-link">1.Batch Normalization</a></li><li class="sidebar-sub-header"><a href="/ml/common/normalization.html#_3-layer-normalization" class="sidebar-link">3.Layer Normalization</a></li><li class="sidebar-sub-header"><a href="/ml/common/normalization.html#_4-group-normalization" class="sidebar-link">4.Group Normalization</a></li><li class="sidebar-sub-header"><a href="/ml/common/normalization.html#_6-instance-normalization" class="sidebar-link">6.Instance Normalization</a></li></ul></li><li><a href="/ml/common/deform-cnn.html" class="sidebar-link">可变形卷积</a></li><li><a href="/ml/common/group-cnn.html" class="sidebar-link">分组卷积</a></li><li><a href="/ml/common/focal-loss.html" class="sidebar-link">Focal Loss</a></li><li><a href="/ml/common/bidcnn.html" class="sidebar-link">Built-in Invariance of DCNN</a></li><li><a href="/ml/common/transformer.html" class="sidebar-link">Transformer 介绍</a></li><li><a href="/ml/common/model-deploy.html" class="sidebar-link">模型量化</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="数据归一化方法bn-ln-gn-in"><a href="#数据归一化方法bn-ln-gn-in" class="header-anchor">#</a> 数据归一化方法BN/LN/GN/IN</h1> <h2 id="_0-introduction"><a href="#_0-introduction" class="header-anchor">#</a> 0. Introduction</h2> <p>在神经网络的训练过程中，网络的收敛情况非常依赖于参数的初始化情况，使用<code>Normalization</code>的方法可以增强模型训练过程中的鲁棒性。目前常用的<code>Normalization</code>方法有<strong>Batch Normalization</strong>、<strong>Layer Normalization</strong>、<strong>Group Normalization</strong>、<strong>Instance Normalization</strong>四种方法，具体分别是指在一个<code>batch</code>的数据上分别在不同维度上做<code>Normalization</code>。如下图：</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/n1norm.jpg" alt=""></p> <p>图中<code>N</code>表示一个<code>Batch</code>的大小，<code>WH</code>表示特征图宽高方向<code>resize</code>到一起后的维度方向，<code>C</code>表示不同的特征通道，<code>G</code>表示在通道方向做<code>Group Normalization</code>时每组包含的通道数的大小。</p> <h2 id="_1-batch-normalization"><a href="#_1-batch-normalization" class="header-anchor">#</a> 1.Batch Normalization</h2> <p><code>Batch Normalization</code>是谷歌的<code>Sergey Ioffe</code>等于2015年03月份提交的论文<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener noreferrer"><code>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</code><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中提出的。</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/n2bn.jpg" alt=""></p> <p>其中<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container>是维度为<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container>的数据，分别求每个维度在<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="a"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="c"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="h"></mjx-c></mjx-mi></mjx-math></mjx-container>方向的均值和方差，然后进行归一化。值得注意的是方程</p> <mjx-container jax="SVG" display="true" class="MathJax" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg xmlns="http://www.w3.org/2000/svg" width="12.676ex" height="2.321ex" role="img" focusable="false" viewBox="0 -810 5602.9 1026" aria-hidden="true" style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.489ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1094.7,0)"><path data-c="2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2372.5,0)"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2915.5,0)"><g data-mml-node="mover"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(449.5,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(4036.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(5036.9,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">←</mo><mi>γ</mi><mrow data-mjx-texclass="ORD"><mover><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">^</mo></mover></mrow><mo>+</mo><mi>β</mi></math></mjx-assistive-mml></mjx-container><p>相当于对归一化后的数据做了线性变换，这里<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B3"></mjx-c></mjx-mi></mjx-math></mjx-container>和<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B2"></mjx-c></mjx-mi></mjx-math></mjx-container>都是在网络训练过程中需要学习的参数。根据上述<code>BN</code>的计算方式可求得反向传播的链路图：</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/n3BNcircuit.jpg" alt=""></p> <p>由此使用<code>Batch Normalization Layer</code>时，其对应的反向和前向推理代码为，参考自<a href="https://cs231n.github.io/assignments2022/assignment2/" target="_blank" rel="noopener noreferrer">CS231N homework2<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：</p> <div class="language-python extra-class"><pre class="language-python"><code>
<span class="token comment">## Forward</span>
<span class="token keyword">def</span> <span class="token function">batchnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> bn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Forward pass for batch normalization.

    During training the sample mean and (uncorrected) sample variance are
    computed from minibatch statistics and used to normalize the incoming data.
    During training we also keep an exponentially decaying running mean of the
    mean and variance of each feature, and these averages are used to normalize
    data at test-time.

    At each timestep we update the running averages for mean and variance using
    an exponential decay based on the momentum parameter:

    running_mean = momentum * running_mean + (1 - momentum) * sample_mean
    running_var = momentum * running_var + (1 - momentum) * sample_var

    Note that the batch normalization paper suggests a different test-time
    behavior: they compute sample mean and variance for each feature using a
    large number of training images rather than using a running average. For
    this implementation we have chosen to use running averages instead since
    they do not require an additional estimation step; the torch7
    implementation of batch normalization also uses running averages.

    Input:
    - x: Data of shape (N, D)
    - gamma: Scale parameter of shape (D,)
    - beta: Shift paremeter of shape (D,)
    - bn_param: Dictionary with the following keys:
      - mode: 'train' or 'test'; required
      - eps: Constant for numeric stability
      - momentum: Constant for running mean / variance.
      - running_mean: Array of shape (D,) giving running mean of features
      - running_var Array of shape (D,) giving running variance of features

    Returns a tuple of:
    - out: of shape (N, D)
    - cache: A tuple of values needed in the backward pass
    &quot;&quot;&quot;</span>
    mode <span class="token operator">=</span> bn_param<span class="token punctuation">[</span><span class="token string">&quot;mode&quot;</span><span class="token punctuation">]</span>
    eps <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;eps&quot;</span><span class="token punctuation">,</span> <span class="token number">1e-5</span><span class="token punctuation">)</span>
    momentum <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;momentum&quot;</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">)</span>

    N<span class="token punctuation">,</span> D <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    running_mean <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;running_mean&quot;</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>D<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>
    running_var <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;running_var&quot;</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>D<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>

    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span>

        avg <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        var <span class="token operator">=</span> x<span class="token punctuation">.</span>var<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        std <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var<span class="token punctuation">)</span>
        x_hat <span class="token operator">=</span> avg <span class="token operator">/</span> <span class="token punctuation">(</span>std <span class="token operator">+</span> eps<span class="token punctuation">)</span>
        out <span class="token operator">=</span> x_hat <span class="token operator">*</span> gamma <span class="token operator">+</span> beta
        
        shape <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;shape&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">)</span><span class="token punctuation">)</span>
        axis <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;axis&quot;</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
        cache <span class="token operator">=</span> x<span class="token punctuation">,</span> avg<span class="token punctuation">,</span> var<span class="token punctuation">,</span> std<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> x_hat<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> shape<span class="token punctuation">,</span> axis

        <span class="token keyword">if</span> axis <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
          running_mean <span class="token operator">=</span> running_mean <span class="token operator">*</span> momentum <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> momentum<span class="token punctuation">)</span> <span class="token operator">*</span> avg
          running_var <span class="token operator">=</span> running_var <span class="token operator">*</span> momentum <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> momentum<span class="token punctuation">)</span> <span class="token operator">*</span> var
    <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">:</span>

        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> running_mean<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>running_var<span class="token punctuation">)</span> <span class="token operator">+</span> eps<span class="token punctuation">)</span>
        out <span class="token operator">=</span> x_hat <span class="token operator">*</span> gamma <span class="token operator">+</span> beta

    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Invalid forward batchnorm mode &quot;%s&quot;'</span> <span class="token operator">%</span> mode<span class="token punctuation">)</span>

    <span class="token comment"># Store the updated running means back into bn_param</span>
    bn_param<span class="token punctuation">[</span><span class="token string">&quot;running_mean&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> running_mean
    bn_param<span class="token punctuation">[</span><span class="token string">&quot;running_var&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> running_var

    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache

<span class="token comment">## Backward</span>
<span class="token keyword">def</span> <span class="token function">batchnorm_backward_alt</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Alternative backward pass for batch normalization.

    For this implementation you should work out the derivatives for the batch
    normalizaton backward pass on paper and simplify as much as possible. You
    should be able to derive a simple expression for the backward pass.
    See the jupyter notebook for more hints.

    Note: This implementation should expect to receive the same cache variable
    as batchnorm_backward, but might not use all of the values in the cache.

    Inputs / outputs: Same as batchnorm_backward
    &quot;&quot;&quot;</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> std<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> x_hat<span class="token punctuation">,</span> _<span class="token punctuation">,</span> shape<span class="token punctuation">,</span> axis <span class="token operator">=</span> cache <span class="token comment"># expand cache</span>
    S <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>                     <span class="token comment"># helper function</span>
    
    dbeta <span class="token operator">=</span> dout<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> order<span class="token operator">=</span><span class="token string">'F'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token punctuation">)</span>            <span class="token comment"># derivative w.r.t. beta</span>
    dgamma <span class="token operator">=</span> <span class="token punctuation">(</span>dout <span class="token operator">*</span> x_hat<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> order<span class="token operator">=</span><span class="token string">'F'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token punctuation">)</span> <span class="token comment"># derivative w.r.t. gamma</span>
    
    dx <span class="token operator">=</span> dout <span class="token operator">*</span> gamma <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dout<span class="token punctuation">)</span> <span class="token operator">*</span> std<span class="token punctuation">)</span>          <span class="token comment"># temporarily initialize scale value</span>
    dx <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dout<span class="token punctuation">)</span><span class="token operator">*</span>dx  <span class="token operator">-</span> S<span class="token punctuation">(</span>dx<span class="token operator">*</span>x_hat<span class="token punctuation">)</span><span class="token operator">*</span>x_hat <span class="token operator">-</span> S<span class="token punctuation">(</span>dx<span class="token punctuation">)</span> <span class="token comment"># derivative w.r.t. unnormalized x</span>

    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta

</code></pre></div><p>在以上代码中，<code>BatchNorm</code>层在训练结束推理时使用的是训练时得到的<code>running average</code>和<code>running variance</code>，在反向传播梯度时是根据链式法则求出<code>BN</code>层整体的梯度公式来计算梯度，可以减少中间变量的存储和计算，减少运算量和内存占用。</p> <h2 id="_3-layer-normalization"><a href="#_3-layer-normalization" class="header-anchor">#</a> 3.Layer Normalization</h2> <p><strong>Batch Normalization</strong>在使用过程中依赖batch size的大小，当模型比较复杂，占用内存过多时很难使用大的<code>batch size</code>进行网络训练，这时BN的效果会受到限制，<code>2016</code>年<code>Hinton</code>等提出的<a href="https://arxiv.org/pdf/1607.06450.pdf" target="_blank" rel="noopener noreferrer">LayerNormalization<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>克服了这些问题，可以作为batch size 较小时<code>Batch Normalization</code>的一种替代方案。</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/n4ln.jpg" alt=""></p> <p>其中，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="H"></mjx-c></mjx-mi></mjx-math></mjx-container>表示当前层隐层单元的数量，当使用的是卷积神经网络时，<code>Layer Normalization</code>是作用在卷积核作用在输入上得到的输出的每个通道上，输出的每个通道算做一层，在该层上做<code>Normalization</code>。</p> <p>代码实现：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">layernorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> ln_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Forward pass for layer normalization.
    During both training and test-time, the incoming data is normalized per data-point,
    before being scaled by gamma and beta parameters identical to that of batch normalization.
    Note that in contrast to batch normalization, the behavior during train and test-time for
    layer normalization are identical, and we do not need to keep track of running averages
    of any sort.
    Input:
    - x: Data of shape (N, D)
    - gamma: Scale parameter of shape (D,)
    - beta: Shift paremeter of shape (D,)
    - ln_param: Dictionary with the following keys:
        - eps: Constant for numeric stability
    Returns a tuple of:
    - out: of shape (N, D)
    - cache: A tuple of values needed in the backward pass
    &quot;&quot;&quot;</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    eps <span class="token operator">=</span> ln_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&quot;eps&quot;</span><span class="token punctuation">,</span> <span class="token number">1e-5</span><span class="token punctuation">)</span>
    ln_param<span class="token punctuation">.</span>setdefault<span class="token punctuation">(</span><span class="token string">'mode'</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">)</span>       <span class="token comment"># same as batchnorm in train mode</span>
    ln_param<span class="token punctuation">.</span>setdefault<span class="token punctuation">(</span><span class="token string">'axis'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>             <span class="token comment"># over which axis to sum for grad</span>
    <span class="token punctuation">[</span>gamma<span class="token punctuation">,</span> beta<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>atleast_2d<span class="token punctuation">(</span>gamma<span class="token punctuation">,</span> beta<span class="token punctuation">)</span> <span class="token comment"># assure 2D to perform transpose</span>

    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> batchnorm_forward<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> gamma<span class="token punctuation">.</span>T<span class="token punctuation">,</span> beta<span class="token punctuation">.</span>T<span class="token punctuation">,</span> ln_param<span class="token punctuation">)</span> <span class="token comment"># same as batchnorm</span>
    out <span class="token operator">=</span> out<span class="token punctuation">.</span>T                                                    <span class="token comment"># transpose back</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">layernorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Backward pass for layer normalization.
    For this implementation, you can heavily rely on the work you've done already
    for batch normalization.
    Inputs:
    - dout: Upstream derivatives, of shape (N, D)
    - cache: Variable of intermediates from layernorm_forward.
    Returns a tuple of:
    - dx: Gradient with respect to inputs x, of shape (N, D)
    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)
    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)
    &quot;&quot;&quot;</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> batchnorm_backward_alt<span class="token punctuation">(</span>dout<span class="token punctuation">.</span>T<span class="token punctuation">,</span> cache<span class="token punctuation">)</span> <span class="token comment"># same as batchnorm backprop</span>
    dx <span class="token operator">=</span> dx<span class="token punctuation">.</span>T <span class="token comment"># transpose back dx</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta
</code></pre></div><p>从上面代码可以看到，<code>Layer Normalization</code>是在每个样本的每层输出上实现的，因此可以复用<code>Batch Normalization</code>的实现。</p> <h2 id="_4-group-normalization"><a href="#_4-group-normalization" class="header-anchor">#</a> 4.Group Normalization</h2> <p><code>Group Normalization</code>是2018年06月份HeKaiMing等提出的<a href="https://arxiv.org/abs/1803.08494" target="_blank" rel="noopener noreferrer">论文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中发表的方法，作为<code>Batch Normalization</code>的另一种替代。</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/n5gn.jpg" alt=""></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">## pytorch example</span>
<span class="token keyword">import</span> torch
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
m <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>GroupNorm<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> m<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>

<span class="token comment"># equal to </span>
gx1 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
gx2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
mu1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>gx1<span class="token punctuation">)</span>
mu2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>gx2<span class="token punctuation">)</span>
std1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>gx1<span class="token punctuation">)</span><span class="token punctuation">)</span>
std2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>gx2<span class="token punctuation">)</span><span class="token punctuation">)</span>
x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> mu1<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>std1  <span class="token operator">+</span> <span class="token number">1e-05</span><span class="token punctuation">)</span>
x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> mu2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>std2 <span class="token operator">+</span> <span class="token number">1e-05</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div><h2 id="_6-instance-normalization"><a href="#_6-instance-normalization" class="header-anchor">#</a> 6.Instance Normalization</h2> <p>Instance Normalization 是2017年1月份<code>Dmitry Ulyanov</code>等发表的论文<a href="https://arxiv.org/abs/1701.02096" target="_blank" rel="noopener noreferrer">Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中的提出的方法，其作用在单个样本的一个通道上，相当于<code>num_groups=1</code>的<code>Group Normalization</code>。</p> <p><img src="https://day-pic-1311699660.cos.ap-nanjing.myqcloud.com/image/n6InstanceNorm.jpg" alt=""></p> <div class="adswrapper"><!----> <div style="display:none;"></div> <ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-8685746128991385" data-ad-slot="2974191661" data-ad-test="" data-ad-region="" class="adsbygoogle" style="display:block;"></ins> <!----> <div style="display:none;"> (adsbygoogle = window.adsbygoogle || []).push({}); </div></div> <h3 id="参考资料"><a href="#参考资料" class="header-anchor">#</a> 参考资料</h3> <blockquote><ul><li><a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" target="_blank" rel="noopener noreferrer">1.https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://github.com/mantasu/cs231n/blob/master/assignment2/cs231n/layers.py" target="_blank" rel="noopener noreferrer">2.https://github.com/mantasu/cs231n/blob/master/assignment2/cs231n/layers.py<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://wandb.ai/wandb_fc/GroupNorm/reports/Group-Normalization-in-Pytorch-With-Examples---VmlldzoxMzU0MzMy" target="_blank" rel="noopener noreferrer">3.Group Normalization in Pytorch (With Examples)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html" target="_blank" rel="noopener noreferrer">4.GROUPNORM<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></blockquote></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/ml/common/nnoptimization.html" class="prev">
        神经网络参数优化
      </a></span> <span class="next"><a href="/ml/common/deform-cnn.html">
        可变形卷积
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.4fb1e7ac.js" defer></script><script src="/assets/js/2.441eb26f.js" defer></script><script src="/assets/js/1.1a1c696e.js" defer></script><script src="/assets/js/221.d10aa87c.js" defer></script>
  </body>
</html>
